<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">Refactoring the Drools Compiler</title><link rel="alternate" href="https://blog.kie.org/2022/07/refactoring-the-drools-compiler.html" /><author><name>Edoardo Vacchi</name></author><id>https://blog.kie.org/2022/07/refactoring-the-drools-compiler.html</id><updated>2022-07-07T14:00:00Z</updated><content type="html">In the past few weeks we have been working hard on redesigning the architecture of Drools the rules engine and the rest of the our ecosystem of runtime engines. In this blog post I want to focus a bit on the refactoring of the KnowledgeBuilder, a core component of the build infrastructure of the v6-v7 APIs. For the ongoing work on Drools 8, we are rethinking the entire design of this and other components. On the latest stable version of the 7 series, that contains logic for processing resources of different types (such as DRL, DMN, BPMN, PMML, XLS etc…) On the main branch, , where most of the fat is really public methods that we kept for backwards compatibility, that are now delegating to new self-contained classes. The main culprit with the KnowledgeBuilderImpl was that it was both the class holding the logic for building assets, and both a sort of "context" object that was passed around to collect pieces of information. The main goals of the refactoring were 1. Refactoring most of the state inside the KnowledgeBuilderImpl into smaller objects with well-defined boundaries 2. Moving the building logic related to the DRL family (plain DRL, XLS, DSLs etc.) to a series smaller, composable 3. Ensuring that each CompilationPhase never referred directly the KnowledgeBuilderImpl The same work involved the CompositeKnowledgeBuilderImpl (which decorates KnowledgeBuilderImpl) and for the ModelBuilderImpl (which subclasses the KnowledgeBuilderImpl). As you can imagine the work was a bit long and iterative, but the good news is that it is now possible to put the CompositePhases in sequence, instantiating them without requiring the entire KnowledgeBuilder, but just its constituent. The KnowledgeBuilderImpl itself now implements by delegating to self-contained objects (e.g. , , ). The phases always refer to such interfaces, e.g., a only refers to a . The result is that now it is possible to put in sequence such phases to produce a: List&lt;CompilationPhase&gt; phases = asList( new ImportCompilationPhase(packageRegistry, packageDescr), new TypeDeclarationAnnotationNormalizer(annotationNormalizer, packageDescr), new EntryPointDeclarationCompilationPhase(packageRegistry, packageDescr), new AccumulateFunctionCompilationPhase(packageRegistry, packageDescr), new TypeDeclarationCompilationPhase(packageDescr, typeBuilder, packageRegistry, null), new WindowDeclarationCompilationPhase(packageRegistry, packageDescr, typeDeclarationContext), new FunctionCompilationPhase(packageRegistry, packageDescr, configuration), new ImmutableGlobalCompilationPhase(packageRegistry, packageDescr, globalVariableContext), new RuleAnnotationNormalizer(annotationNormalizer, packageDescr), new RuleValidator(packageRegistry, packageDescr, configuration), new ImmutableFunctionCompiler(packageRegistry, packageDescr, rootClassLoader), new ImmutableRuleCompilationPhase(packageRegistry, packageDescr, parallelRulesBuildThreshold, attributesForPackage, resource, typeDeclarationContext), new ConsequenceCompilationPhase(packageRegistryManager) ); The same is true both for the traditional in-memory compiler, and . This huge refactoring makes it possible to reuse most of the logic in the traditional compilation flow in a new compiler architecture that is currently being worked on. Stay tuned for more details! The post appeared first on .</content><dc:creator>Edoardo Vacchi</dc:creator></entry><entry><title>Add an Infinispan cache to your ASP.NET application</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/07/add-infinispan-cache-your-aspnet-application" /><author><name>Vittorio Rigamonti</name></author><id>290f5459-e17a-43b6-ae71-20d8acf9484e</id><updated>2022-07-07T07:00:00Z</updated><published>2022-07-07T07:00:00Z</published><summary type="html">&lt;p&gt;The open source &lt;a&gt;Infinispan&lt;/a&gt; data store is popular for in-memory operations. A &lt;a href="https://developers.redhat.com/topics/dotnet"&gt;.NET Core&lt;/a&gt; application can now easily integrate Infinispan as a caching service or session provider. This article provides basic information on how to do that in &lt;a href="https://developers.redhat.com/topics/c"&gt;C#&lt;/a&gt; on &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;What you need:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;.NET 6.0+ installed on your system&lt;/li&gt; &lt;li&gt;Access to get packages from &lt;a href="https://www.nuget.org"&gt;NuGet&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Access to an Infinispan server&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;On the Infinispan server, create a cache named &lt;code&gt;default&lt;/code&gt; listening on the loopback host and port 127.0.0.1:11222, without authentication.&lt;/p&gt; &lt;h2&gt;Create the application&lt;/h2&gt; &lt;p&gt;You are going to work on an &lt;a href="https://docs.microsoft.com/en-us/aspnet/core/?view=aspnetcore-6.0"&gt;ASP.NET Core&lt;/a&gt; application, so run the following command to generate a new application scaffold:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;dotnet new webapp -lang 'C#' -n Infinispan.Example.Caching -f net6.0&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This command creates a new folder with an empty but working ASP.NET Core application. Run the application as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;cd Infinispan.Example.Caching dotnet run&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Check the application's log message for its HTTP or HTTPS URL and enter it into your browser to see the application's display.&lt;/p&gt; &lt;h2&gt;Add Infinispan as a cache&lt;/h2&gt; &lt;p&gt;The application requires the Infinispan caching package, so add it as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;dotnet add package Infinispan.Hotrod.Caching --version 0.0.1-alpha3&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This package provides an IDistibutedCache implementation based on the Infinispan C# client, imported as a dependency.&lt;/p&gt; &lt;h2&gt;Set up Infinispan as a cache provider&lt;/h2&gt; &lt;p&gt;An ASP.NET Core application (6.0) provides all the services and pipeline setup in the &lt;code&gt;Program.cs&lt;/code&gt; file. To this file, you need to add the Infinispan client configuration in the service setup, as well as session management in the process pipeline. Set the cache entries to expire after 10 seconds of idle time. &lt;code&gt;Program.cs&lt;/code&gt; should now look like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-diff"&gt;using Infinispan.Hotrod.Core; using Infinispan.Hotrod.Caching.Distributed; var builder = WebApplication.CreateBuilder(args); // Add services to the container. // Infinispan default setup is used: // 127.0.0.1:11222 cacheName: default builder.Services.AddInfinispanCache(); builder.Services.AddSession(options =&gt; { options.IdleTimeout = TimeSpan.FromSeconds(10); options.Cookie.HttpOnly = true; options.Cookie.IsEssential = true; }); builder.Services.AddRazorPages(); var app = builder.Build(); // Configure the HTTP request pipeline. if (!app.Environment.IsDevelopment()) { app.UseExceptionHandler("/Error"); // The default HSTS value is 30 days. You may want to change this for production scenarios, see https://aka.ms/aspnetcore-hsts. app.UseHsts(); } app.UseHttpsRedirection(); app.UseStaticFiles(); app.UseRouting(); app.UseAuthorization(); app.UseSession(); app.MapRazorPages(); app.Run();&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Add business code&lt;/h2&gt; &lt;p&gt;Our business code is very simple: It presents some information (the user name, the age of the session, and the first access time) to the user as a result of a request. The data is fetched from the session cache if available there and computed by the program otherwise. This logic is implemented in the model file &lt;code&gt;Pages/Index.cshtml.cs&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-cs"&gt;using Microsoft.AspNetCore.Mvc; using Microsoft.AspNetCore.Mvc.RazorPages; namespace Infinispan.Example.Caching.Pages { public class IndexModel : PageModel { private readonly ILogger&lt;IndexModel&gt; _logger; public IndexModel(ILogger&lt;IndexModel&gt; logger) { _logger = logger; } public const string SessionKeyName = "_Name"; public const string SessionKeyAge = "_Age"; public const string SessionKeyFirstAccess = "_FirstAccess"; public static Random RndSource = new Random(); public string DataSource { get; private set; } = ""; public void OnGet() { // Requires: using Microsoft.AspNetCore.Http; if (string.IsNullOrEmpty(HttpContext.Session.GetString(SessionKeyName))) { DataSource = "Computed"; HttpContext.Session.SetString(SessionKeyName, "Mickey"); HttpContext.Session.SetInt32(SessionKeyAge, RndSource.Next(100)); HttpContext.Session.SetString(SessionKeyFirstAccess, DateTime.Now.ToString()); return; } DataSource = "Cache"; } } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The output is generated from a file named &lt;code&gt;Pages/Index.cshtml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;@page @using Infinispan.Example.Caching.Pages @using Microsoft.AspNetCore.Http @model IndexModel @{ ViewData["Title"] = "Home page"; } &lt;div class="text-center"&gt; &lt;h1 class="display-4"&gt;Welcome&lt;/h1&gt; &lt;h2&gt;The time on the server is @DateTime.Now&lt;/h2&gt; &lt;h2&gt;Name (@Model.DataSource): @HttpContext.Session.GetString(IndexModel.SessionKeyName)&lt;/h2&gt; &lt;h2&gt;Age (@Model.DataSource): @HttpContext.Session.GetInt32(IndexModel.SessionKeyAge)&lt;/h2&gt; &lt;h2&gt;First Access Date (@Model.DataSource): @HttpContext.Session.GetString(IndexModel.SessionKeyFirstAccess)&lt;/h2&gt; &lt;p&gt;Learn about &lt;a href="https://docs.microsoft.com/aspnet/core"&gt;building Web apps with ASP.NET Core&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Easy ASP.NET access to Infinispan&lt;/h2&gt; &lt;p&gt;Everything is now in place for the show. Run your application again and check the output in the browser. The &lt;code&gt;Age &lt;/code&gt;and the &lt;code&gt;First Access Date&lt;/code&gt; field are computed the first time and cached for 10 seconds. The session itself expires after 10 seconds of idle time, as configured in the services configuration. Therefore, the cached values are reused by the application if requests come in quick succession.&lt;/p&gt; &lt;p&gt;This article has demonstrated how easily you can integrate Infinispan as a distributed cache and session provider for ASP.Net Core applications.&lt;/p&gt; &lt;p&gt;Explore more .NET tutorials on Red Hat Developer:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/21/hello-podman-using-net"&gt;Hello Podman using .NET&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/02/22/debug-net-applications-running-local-containers-vs-code"&gt;Debug .NET applications running in local containers with VS Code&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/07/07/deploy-net-applications-red-hat-openshift-using-helm"&gt;Deploy .NET applications on Red Hat OpenShift using Helm&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/07/add-infinispan-cache-your-aspnet-application" title="Add an Infinispan cache to your ASP.NET application"&gt;Add an Infinispan cache to your ASP.NET application&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Vittorio Rigamonti</dc:creator><dc:date>2022-07-07T07:00:00Z</dc:date></entry><entry><title type="html">Eclipse Vert.x 4.3.2 released!</title><link rel="alternate" href="https://vertx.io/blog/eclipse-vert-x-4-3-2" /><author><name>Julien Viet</name></author><id>https://vertx.io/blog/eclipse-vert-x-4-3-2</id><updated>2022-07-07T00:00:00Z</updated><content type="html">Eclipse Vert.x version 4.3.2 has just been released. It fixes quite a few bugs that have been reported by the community and provides a couple of features. In addition it provides support for virtual threads incubation project.</content><dc:creator>Julien Viet</dc:creator></entry><entry><title type="html">Creating Prometheus Dashboards using Dashbuilder</title><link rel="alternate" href="https://blog.kie.org/2022/07/creating-prometheus-dashboards-using-dashbuilder.html" /><author><name>William Siqueira</name></author><id>https://blog.kie.org/2022/07/creating-prometheus-dashboards-using-dashbuilder.html</id><updated>2022-07-06T15:27:00Z</updated><content type="html">is a client tool for building dashboards and can consume data from any JSON source including Prometheus! It runs without a server requirement and the dashboard definition uses . You can run YML in an or create a static website as described in the .  In this article we will describe how to create Dashbuilder dashboards for Prometheus and share some samples so you can get started creating your own dashboards. PROMETHEUS HTTP API AND PROMQL Prometheus can be accessed using HTTP  to execute PromQL queries and have results in JSON format. The result of HTTP calls can have different types: Instant vector, Range vector and Scalar. According to the result type then we need to transform to the format supported by Dashbuilder. Dashbuilder can consume any as a dataset or a more complex object to include metadata. To transform results we need to use a expression, which may seem complex at a first glance, but once it is built we do not have to modify it anymore. Here’s the simplest dashboard that uses an expression that can be reused for any Prometheus dashboard: properties: prometheusUrl: http://localhost:9090 query: 1 parse: &gt;- &gt;- $.data.( { "columns": result[0].( [ {"id" : "timestamp", "type": "number"}, {"id" : "value", "type": "number"}, $keys(metric).({"id" : $, "type": "label"}) ]; ), "values": ( resultType = "scalar" ? [result[0] * 1000, result[1]] : resultType = "matrix" ? result.( $metric := metric.*; values.[ $[0] * 1000, $[1], $metric ] ) : resultType = "vector" ? result.[ value[0] * 1000, value[1], metric.* ] ) } ) datasets: - uuid: prometheus expression: ${parse} url: ${prometheusUrl}/api/v1/query?query=${query} pages: - components: - settings: lookup: uuid: prometheus This specific expression can be modified if needed. Since it is set as an expression then you can reuse it for all datasets you are creating. VISUAL COMPONENTS To show data we have multiple that can be declared .  A common component to be used with Prometheus is timeseries. This component only requires 3 columns from the dataset:  1. series: a column with values that will be used as the series; 2. timestamp: the timestamp column in javascript supported formats (the expression used above handle this) 3. value: The value used in axis Y Here’s a timeseries for the query prometheus_http_requests_total[1h:10s] filtering only successful HTTP requests: - settings: component: timeseries refresh: interval: "2" timeseries: title: text: Successful Responses to Prometheus external: width: 100% height: 400px lookup: uuid: prometheus filter: - column: code function: EQUALS_TO args: - 200 group: - functions: - source: handler - source: timestamp - source: value We can show total values using components that allow us to show a specific value which can be the result of an aggregation operation, such as sum or average. Here’s for example 3 cards in a row summarizing http requests received by prometheus: columns: - span: "4" components: - settings: type: METRIC general: title: "All" visible: "true" chart: height: "90" columns: - id: value pattern: "#,000" lookup: uuid: http_requests group: - functions: - source: value function: SUM - span: "4" components: - settings: type: METRIC general: title: "Success" visible: "true" chart: height: "90" columns: - id: value pattern: "#,000" lookup: uuid: http_requests filter: - column: code function: EQUALS_TO args: - 200 group: - functions: - source: value function: SUM - span: "4" components: - settings: type: METRIC general: title: "Others" visible: "true" chart: height: "90" columns: - id: value pattern: "#,000" lookup: uuid: http_requests filter: - column: code function: NOT_EQUALS_TO args: - 200 group: - functions: - source: value function: SUM    Finally we can add a filter component to allow us to read metrics about a specific handler: - components: - html: &lt;h1&gt; Prometheus HTTP Requests&lt;/h1&gt; &lt;hr/&gt; - html: "Filter" properties: font-weight: bolder - properties: width: "150px" margin-bottom: 30px settings: type: SELECTOR refresh: interval: "${refreshInterval}" filter: enabled: "true" notification: "true" lookup: uuid: recent_http_requests group: - columnGroup: source: handler functions: - source: handler We can make the report real time by adding a refresh interval to each component and to avoid concurrent requests we can also add cache to our dataset. Adding all together we have the following report: Check the code for the dashboard above in . CONCLUSION Dashbuilder highlights that it can run without the requirement of a server installation and has a comprehensive YML guide, which makes it a great tool for creating dashboards for Prometheus.  For more examples check the ! The post appeared first on .</content><dc:creator>William Siqueira</dc:creator></entry><entry><title>What qualifies for Red Hat Developer Subscription for Teams?</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/06/what-qualifies-red-hat-developer-subscription-teams" /><author><name>Josh Swanson, Brian Gollaher</name></author><id>d60e8bf3-bc55-40a1-9b6c-cb96c30b3df5</id><updated>2022-07-06T07:00:00Z</updated><published>2022-07-06T07:00:00Z</published><summary type="html">&lt;p&gt;Recently, Red Hat &lt;a href="https://developers.redhat.com/articles/2022/05/10/access-rhel-developer-teams-subscription"&gt;relaunched&lt;/a&gt; the Developer Subscription for Teams, enabling organizations &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;already running other Red Hat technologies to&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; access &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; for their development activities without friction. In this article, we clarify what Red Hat defines as development activities and highlight some exciting use cases for the Developer Subscription for Teams.&lt;/p&gt; &lt;h2&gt;What activities are considered development use?&lt;/h2&gt; &lt;p&gt;Figure 1 calls out the delimitation between development and production activities according to &lt;a href="https://www.redhat.com/en/about/agreements"&gt;Appendix 1&lt;/a&gt; of the Red Hat license agreement. To begin breaking this down, let’s start at the far left end, where systems would leverage the Developer Subscription for Teams.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Development-Use-Cases_diagram.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/Development-Use-Cases_diagram.png?itok=VAp0P1Op" width="1440" height="422" alt="Development activities grouped under RHEL Developer for Teams and production activities grouped under RHEL." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: How activities are categorized for development and production according to the Red Hat Enterprise Agreements.&lt;/figcaption&gt; &lt;/figure&gt; &lt;h2&gt;An example application&lt;/h2&gt; &lt;p&gt;Let’s consider a fairly simple yet mission-critical application: a tax calculator. When most businesses run transactions for goods and services, the appropriate taxes must be calculated and added to the total purchase price. Our example application consists of three parts:&lt;/p&gt; &lt;ul&gt; &lt;li aria-level="1"&gt;A database that stores the appropriate tax information and rates.&lt;/li&gt; &lt;li aria-level="1"&gt;A middle tier that retrieves tax information from the database and performs calculations.&lt;/li&gt; &lt;li aria-level="1"&gt;A front-end system running a RESTful API that’s used to interact with the application.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These three tiers come together to form our tax application. They will be the basis for considering how the Developer Subscription for Teams enables the rapid development, testing, and deployment of this application. Now we’ll walk through each phase, as illustrated in Figure 1.&lt;/p&gt; &lt;h2&gt;Software design and coding&lt;/h2&gt; &lt;p&gt;When developing, updating, or maintaining this tax application, there are often design phases meant to outline the intended end state: functionality, architecture, features, and components. Once the design is accepted, then the actual work of writing the code begins. The systems used for designing a new application or upgrading an existing one with new features, overhauling legacy code, squashing bugs, etc., would all be covered by the Developer Subscription for Teams.&lt;/p&gt; &lt;h2&gt;Building&lt;/h2&gt; &lt;p&gt;Once the code for our tax application is written, we might need to build the application, which means pulling in dependencies, setting appropriate values, and outputting them into a form that can easily be deployed. We might also need to build multiple deployment packages that can be deployed across multiple systems in multiple environments and compute spaces, such as a cloud provider or on-premise datacenter.&lt;/p&gt; &lt;p&gt;Since this action might require more computational power than what a standard workstation provides, it makes sense to leverage the capabilities of a hyperscaler. The systems we use to build the application would also qualify for the Developer Subscription for Teams.&lt;/p&gt; &lt;h2&gt;Unit testing&lt;/h2&gt; &lt;p&gt;Our three-tier tax application, composed of three parts (a database, a middle tier, and a front-end API), can be broken apart and tested individually, allowing for more thorough testing of the components and more targeted testing.&lt;/p&gt; &lt;p&gt;Our database can be loaded with the appropriate tax information and then put through a schema update test to ensure tax information can be updated without application downtime.&lt;/p&gt; &lt;p&gt;Second, our middle tier can be put through a load test to demonstrate expected response times and validate that multiple calculations can be run simultaneously without causing calculation collisions.&lt;/p&gt; &lt;p&gt;Finally, our front-end API’s role-based access control (RBAC) functionality can be tested to ensure only requests coming from the appropriate systems are accepted and sent to be processed by the application, and that the API returns the results in a data format that other applications can easily consume.&lt;/p&gt; &lt;p&gt;What’s unique about this specific step in the software development life cycle is that the number of systems needed to properly test and validate each unit of the application increases almost exponentially. A database system is necessary, and we also need a system to run some test transactions via a connection to the database while another system is running a schema update. Our middle-tier system needs multiple other systems connected and requesting taxes be calculated while being able to reference an external source of controlled data to ensure calculations are accurate. Finally, our API needs to be receiving requests from different sources, some of which are allowed via RBAC rules and some that are not, while being able to return consumable data to those authorized sources.&lt;/p&gt; &lt;h2&gt;System integration and integration testing&lt;/h2&gt; &lt;p&gt;At this step in the software development life cycle, we start to put the puzzle pieces of our application landscape together. Here, we’ll combine our example tax application with our existing point-of-sale application, our ledger application, our inventory tracking application, and so on. All these applications must work together successfully for our customers to be able to make a purchase, so testing and validation of the integration of these various applications is crucial.&lt;/p&gt; &lt;p&gt;First, we can spin up the other applications and ensure they’re communicating with each other; then, we can add in our example tax application. Once the appropriate API endpoints are specified, RBAC rules are written, and network communication is validated, we can test running real-world transactions through our system and look for any piece of the puzzle that isn’t working or is blocking a successful purchase. We can also use real-world data here to ensure our test environment completes the purchase as expected.&lt;/p&gt; &lt;h2&gt;Pre-prod testing&lt;/h2&gt; &lt;p&gt;Here, we develop, test, and practice the steps needed to safely introduce our new example tax application to our production environment in a space that closely resembles it. We’ll walk through identifying what outages are required and what impact that will have on our business, as well as clearly documenting any steps that need to be taken by teams to deploy our new tax application successfully. These steps can be tested multiple times for training and practice purposes in this environment without impacting production.&lt;/p&gt; &lt;p&gt;An environment such as this is often a scaled-down version of production that is constantly running, and has multiple teams that can access and leverage it for various activities. Again, the Developer Subscription for Teams covers this environment, removing the subscription barrier to entry and having an appropriate place to test the introduction of our tax application to production.&lt;/p&gt; &lt;h2&gt;Push to production&lt;/h2&gt; &lt;p&gt;Here’s where we cross the bridge from the Developer Subscription for Teams into “production” Red Hat Enterprise Linux subscriptions. Let’s say our organization uses a combination of continuous integration/continuous delivery (CI/CD) pipelines and &lt;a href="https://developers.redhat.com/articles/2022/05/26/whats-new-ansible-automation-platform-22"&gt;Red Hat Ansible Automation Platform&lt;/a&gt; to deploy our applications in production from our code repository. The two are closely integrated to perform the steps we identified during testing in our pre-prod environment.&lt;/p&gt; &lt;p&gt;Our Red Hat Ansible Automation Platform subscriptions would cover the automation piece of the push-to-production story, and production. Red Hat Enterprise Linux subscriptions would cover the systems running our code repository and CI/CD pipelines, because our production code is flowing through them. Like the Developer Subscription for Teams, most production Red Hat Enterprise Linux subscriptions are cloud-eligible, meaning that these systems can run on-premise or off, and in the case of the CI/CD pipelines, can be spun up in a cloud on-demand to support our deployment activities.&lt;/p&gt; &lt;h2&gt;Monitor&lt;/h2&gt; &lt;p&gt;These systems are the watchers on the (proverbial) wall: constantly checking in on our various production and pre-production systems, ensuring they’re up and running as expected. Should a system go down or become unresponsive, these systems are responsible for identifying the downed system(s), attempting to recover services automatically, and, if that fails, reaching out for human intervention to restore functionality via various communication systems such as email or chat notifications. The systems watching for outages, attempting automatic recovery, and transporting outage notifications would consume production Red Hat Enterprise Linux subscriptions.&lt;/p&gt; &lt;h2&gt;Update and maintain&lt;/h2&gt; &lt;p&gt;The last block called out in Figure 1 encompasses systems used to keep our production environment running and healthy. These could be systems dedicated to storing updates for our systems (such as Red Hat Satellite) as well as systems used to apply these updates across our landscape (such as Red Hat Ansible Automation Platform). Other systems used to support these actions, such as bastion servers, proxies for downloading updates, and systems hosting firmware updates or other update packages, would also fall into this category, leveraging a production Red Hat Enterprise Linux subscription.&lt;/p&gt; &lt;p&gt;For a more condensed view of various systems and their respective subscription, here’s a quick reference table:&lt;/p&gt; &lt;div&gt; &lt;table cellspacing="0"&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;&lt;strong&gt;System purpose&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;strong&gt;Subscription type&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Code validation and testing system&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Developer Subscription for Teams&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Load generating server for testing&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Developer Subscription for Teams&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Testing database with production data&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Developer Subscription for Teams&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Build server that creates app RPMs&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Developer Subscription for Teams&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;API endpoint testing system&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Developer Subscription for Teams&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Outage email server&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Production subscription&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Code repository&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Production subscription&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;CI/CD pipeline systems&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Production subscription&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Firmware download proxy&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Production subscription&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The Developer Subscription for Teams is a powerful option for software development and testing in an organization, allowing for easy consumption of Red Hat Enterprise Linux in the spirit of building and testing new and existing applications.&lt;/p&gt; &lt;p&gt;If you’re interested in the Developer Subscription for Teams, &lt;a href="https://www.redhat.com/en/contact?sc_cid=7013a000003163VAAQ"&gt;reach out to a Red Hatter today&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/06/what-qualifies-red-hat-developer-subscription-teams" title="What qualifies for Red Hat Developer Subscription for Teams?"&gt;What qualifies for Red Hat Developer Subscription for Teams?&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Josh Swanson, Brian Gollaher</dc:creator><dc:date>2022-07-06T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus 2.10.2.Final released - Maintenance release</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-2-10-2-final-released/" /><author><name>Guillaume Smet</name></author><id>https://quarkus.io/blog/quarkus-2-10-2-final-released/</id><updated>2022-07-06T00:00:00Z</updated><content type="html">Summer is here but we keep releasing Quarkus at a steady pace: today, we released Quarkus 2.10.2.Final, the second maintenance release of our 2.10 release train. It is a safe upgrade for anyone already using 2.10. If you are not using 2.10 already, please refer to the 2.10 migration guide....</content><dc:creator>Guillaume Smet</dc:creator></entry><entry><title>Write a SystemTap script to trace code execution on Linux</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/05/write-systemtap-script-trace-code-execution-linux" /><author><name>William Cohen</name></author><id>6519b4dd-d8da-4ff5-a3b5-86e01a7fc42d</id><updated>2022-07-05T07:00:00Z</updated><published>2022-07-05T07:00:00Z</published><summary type="html">&lt;p&gt;This is the second article in a two-part series about &lt;a href="https://sourceware.org/systemtap/"&gt;SystemTap&lt;/a&gt;, a tool for adding instrumentation to &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; systems to better understand the behavior of the kernel and of userspace applications or libraries. The &lt;a href="https://developers.redhat.com/articles/2022/06/27/use-systemtap-example-script-trace-kernel-code-operation"&gt;first article&lt;/a&gt; used an existing example script called &lt;code&gt;linetimes.stp&lt;/code&gt; to uncover a possible performance problem.&lt;/p&gt; &lt;p&gt;Now we'll show how SystemTap determines where to place the instrumentation, a few common SystemTap coding techniques, how the &lt;code&gt;linetimes.stp&lt;/code&gt; script was created, and some issues encountered when implementing the script.&lt;/p&gt; &lt;h2&gt;How does linetimes.stp work?&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://developers.redhat.com/blog/2021/01/07/debuginfo-is-not-just-for-debugging-programs"&gt;debugging information&lt;/a&gt; produced by the compiler contains several different pieces of information, including the regions occupied by functions and output mapping machine instructions back to the files and lines of source code.&lt;/p&gt; &lt;p&gt;Multiple machine-language instructions can be associated with a particular line of code. The compiler marks the appropriate instruction that represents the start of a statement in the line information. The script probes each statement start using the following statement:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;probe $1.statement(@2 "@*:*")&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;$1&lt;/code&gt; will be filled in with the first argument passed to the script, indicating what binary (the kernel, a kernel module, or a userspace application) is being instrumented. The &lt;code&gt;@2&lt;/code&gt; will be filled in by the second argument passed to the script: the name of the function being instrumented. The at symbol (&lt;code&gt;@&lt;/code&gt;) indicates that the second argument should be converted to a string. The &lt;code&gt;$1&lt;/code&gt; argument requires no conversion and remains as is.&lt;/p&gt; &lt;p&gt;The string &lt;code&gt;@*:*&lt;/code&gt; specifies a wildcard probe, requesting all filenames through the first asterisk and all line numbers through the second asterisk.&lt;/p&gt; &lt;p&gt;Now that we have the probes, the next step is to create a probe handler that computes the times between the successive probes, accumulates those times, and tracks the control flow through the program. The script needs some state information stored in global associative arrays. The elapsed times (in an array called &lt;code&gt;times&lt;/code&gt;) and last probe point seen (in an array called &lt;code&gt;last_pp&lt;/code&gt;) need to be tracked on a per-thread basis. The probe handler uses the thread ID, &lt;code&gt;tid()&lt;/code&gt;, to access those associative arrays and keep information about each thread distinct.&lt;/p&gt; &lt;p&gt;By default, if there is no entry in the associative array for a key, the value 0 is returned when the program tries to read the entry. To avoid computing a negative elapsed time by subtracting the current time from 0, you need to check that &lt;code&gt;times[pid()]&lt;/code&gt; has a non-zero value. A non-zero time value indicates that an earlier probe on the thread was triggered, so there is information about the time in &lt;code&gt;times&lt;/code&gt; and the previous probe point in &lt;code&gt;last_pp&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The body of the &lt;code&gt;if&lt;/code&gt; statement in the following probe handler computes the elapsed time, &lt;code&gt;e&lt;/code&gt;. The times are accumulated in the &lt;code&gt;region&lt;/code&gt; statistical associative array with the &lt;code&gt;&lt;&lt;&lt;&lt;/code&gt; operator. The probe point stored in &lt;code&gt;last_pp&lt;/code&gt; is used as a key to group together times with the same starting line.&lt;/p&gt; &lt;p&gt;The last statement in the body of the &lt;code&gt;if&lt;/code&gt; statement records the path from the previous probe location (&lt;code&gt;last_pp[tid()]&lt;/code&gt;) to the current probe location (&lt;code&gt;pp()&lt;/code&gt;) in the &lt;code&gt;cfg&lt;/code&gt; associative array. Following the &lt;code&gt;if&lt;/code&gt; statement, the probe handler ends by updating the &lt;code&gt;times&lt;/code&gt; and &lt;code&gt;last_pp&lt;/code&gt; entries for the thread:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;global times, last_pp, region, cfg probe $1.statement(@2 "@*:*") { t = gettimeofday_us() s = times[tid()] if (s) { e = t - s region[last_pp[tid()]] &lt;&lt;&lt; e cfg[last_pp[tid()], pp()] &lt;&lt;&lt; 1 } times[tid()] = t last_pp[tid()] = pp() }&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Properly handling function returns&lt;/h3&gt; &lt;p&gt;One situation the script needs to address is leaving the function via a return and then having the function called again. With just the probe shown previously, the script would include the time between the last statement before the function return and the first statement executed on the next call to the function. To avoid this error, the script needs to have a probe similar to the previous one, but on the function return. The main difference between the two is that the return probe removes the &lt;code&gt;times&lt;/code&gt; and &lt;code&gt;last_pp&lt;/code&gt; entries from the associative arrays to avoid computing the unwanted interval.&lt;/p&gt; &lt;p&gt;This design results in the following probe. As before, &lt;code&gt;$1&lt;/code&gt; indicates whether the instrumented binary is the kernel, a kernel module, or a userspace binary, and &lt;code&gt;@2&lt;/code&gt; is the function name:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;probe $1.function(@2).return { t = gettimeofday_us() s = times[tid()] if (s) { e = t - s region[last_pp[tid()]] &lt;&lt;&lt; e cfg[last_pp[tid()], pp()] &lt;&lt;&lt; 1 } delete times[tid()] delete last_pp[tid()] }&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Counting the function entries&lt;/h3&gt; &lt;p&gt;To gauge the relative frequency of paths through the code, one would like to know the number of times the function is called. This information is recorded in a global variable (&lt;code&gt;calls&lt;/code&gt;) and the following one-line probe that counts each time the function is entered. This probe uses the statistics operator (&lt;code&gt;&lt;&lt;&lt;&lt;/code&gt;) for efficiency, because multiple probes can operate concurrently without locking:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;global calls probe $1.function(@2).call { calls &lt;&lt;&lt; 1 }&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Generating the results&lt;/h3&gt; &lt;p&gt;One last probe is needed to generate the output when the script exits. This task is implemented with an end probe. The output is generated using &lt;code&gt;printf&lt;/code&gt; statements. The SystemTap &lt;code&gt;printf&lt;/code&gt; allows formatting with field width and justification. The &lt;code&gt;%-58s&lt;/code&gt; in the third &lt;code&gt;printf&lt;/code&gt; left-justifies the output of a string printed in a 58-character wide field, and the following two &lt;code&gt;%10d&lt;/code&gt; entries format two right-justified decimal numbers in 10-character wide fields.&lt;/p&gt; &lt;p&gt;There are two sections of code. The first section prints out the headers for the region information, then uses a &lt;code&gt;foreach&lt;/code&gt; loop to print a line with the statistical average and maximum time recorded for each region. The loop variable is &lt;code&gt;p&lt;/code&gt; and the &lt;code&gt;+&lt;/code&gt; sign indicates that the loop should sort the values of &lt;code&gt;p&lt;/code&gt; in ascending order. In this case, output is in the same order as the lines in the source code.&lt;/p&gt; &lt;p&gt;The second section prints the control flow graph information, which is implemented with nested &lt;code&gt;foreach&lt;/code&gt; loops. The outer loop prints each line executed, and the inner loop prints out all the lines that were executed immediately following it, with a count of the executions:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;probe end { printf("\n%s %s call count: %d\n", @1, @2, @count(calls)); printf("\n%-58s %10s %10s\n", "region", "avg(us)", "max(us)"); foreach (p+ in region) { printf("%-58s %10d %10d\n", p, @avg(region[p]), @max(region[p])); } printf("\n\ncontrol flow graph information\n") printf("from\n\tto\n=======================\n") foreach ([src+] in region) { printf("%-s\n", src) foreach ([s,dest+] in cfg[src,*]) { # slice for all dest's printf("\t%-s %d\n", dest, @count(cfg[src,dest])); } } }&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Putting the script together&lt;/h3&gt; &lt;p&gt;All the previous pieces of code have been assembled into a single file in &lt;code&gt;/usr/share/systemtap/examples/process/linetimes.stp&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;#! /usr/bin/env stap # # Copyright (C) 2010-2015 Red Hat, Inc. # Written by William Cohen &lt;wcohen@redhat.com&gt; # # The linetimes.stp script takes two arguments: where to find the function # and the function name. linetimes.stp will instrument each line in the # function. It will print out the number of times that the function is # called, a table with the average and maximum time each line takes, # and control flow information when the script exits. # # For example all the lines of the do_unlinkat function: # # stap linetimes.stp kernel do_unlinkat global calls, times, last_pp, region, cfg probe $1.function(@2).call { calls &lt;&lt;&lt; 1 } probe $1.function(@2).return { t = gettimeofday_us() s = times[tid()] if (s) { e = t - s region[last_pp[tid()]] &lt;&lt;&lt; e cfg[last_pp[tid()], pp()] &lt;&lt;&lt; 1 } delete times[tid()] delete last_pp[tid()] } probe $1.statement(@2 "@*:*") { t = gettimeofday_us() s = times[tid()] if (s) { e = t - s region[last_pp[tid()]] &lt;&lt;&lt; e cfg[last_pp[tid()], pp()] &lt;&lt;&lt; 1 } times[tid()] = t last_pp[tid()] = pp() } probe end { printf("\n%s %s call count: %d\n", @1, @2, @count(calls)); printf("\n%-58s %10s %10s\n", "region", "avg(us)", "max(us)"); foreach (p+ in region) { printf("%-58s %10d %10d\n", p, @avg(region[p]), @max(region[p])); } printf("\n\ncontrol flow graph information\n") printf("from\n\tto\n=======================\n") foreach ([src+] in region) { printf("%-s\n", src) foreach ([s,dest+] in cfg[src,*]) { # slice for all dest's printf("\t%-s %d\n", dest, @count(cfg[src,dest])); } } }&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Limitations&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;linetimes.stp&lt;/code&gt; script is useful, but suffers from several limitations:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The measurements include overhead from the probe handlers. The line of code being measured might only be a few instructions, whereas the probe hander's overhead is significantly more. The script is therefore most useful when a line of code calls a function and you are trying to determine which calls are slower and faster in the function.&lt;/li&gt; &lt;li&gt;The script can't monitor inline functions, because the probes for function entry (&lt;code&gt;probe $1.function(@2).call&lt;/code&gt;) and return (&lt;code&gt;probe $1.function(@2).return&lt;/code&gt;) are not available for inline functions. This limitation extends farther than it might look, because compiler optimization can implicitly make functions inline even if they aren't explicitly specified as inline by the developer.&lt;/li&gt; &lt;li&gt;Compiler reordering of statements can lead to some unexpected sequences in the control flow graph.&lt;/li&gt; &lt;li&gt;Recursive functions can't be probed. If the script monitors a function using recursion, one would see the line with the call followed by the line that is the entry point of the function. However, each time the function returns, the probe clears data and doesn't properly track the times for statements following the return.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;When you encounter a system problem in the future, take a look at the &lt;a href="https://sourceware.org/systemtap/examples/keyword-index.html"&gt;SystemTap examples&lt;/a&gt; to see whether there's an existing script that might help you diagnose the problem or provide a good starting point to create your own bespoke instrumentation. You can also learn more about SystemTap on the upstream project's &lt;a href="https://sourceware.org/systemtap/"&gt;home page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/05/write-systemtap-script-trace-code-execution-linux" title="Write a SystemTap script to trace code execution on Linux"&gt;Write a SystemTap script to trace code execution on Linux&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>William Cohen</dc:creator><dc:date>2022-07-05T07:00:00Z</dc:date></entry><entry><title>JBoss Tools for Eclipse 2022-06</title><link rel="alternate" type="text/html" href="https://tools.jboss.org/blog/4.24.0.final.html" /><category term="release" /><category term="jbosstools" /><category term="devstudio" /><category term="jbosscentral" /><category term="codereadystudio" /><author><name>jeffmaury</name></author><id>https://tools.jboss.org/blog/4.24.0.final.html</id><updated>2022-07-06T12:07:23Z</updated><published>2022-07-04T00:00:00Z</published><content type="html">&lt;div&gt;&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Happy to announce 4.24.0.Final build for Eclipse 2022-06.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Downloads available at &lt;a href="https://tools.jboss.org/downloads/jbosstools/2022-06/4.24.0.Final.html"&gt;JBoss Tools 4.24.0.Final&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-is-new"&gt;&lt;a class="anchor" href="#what-is-new"&gt;&lt;/a&gt;What is New?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Full info is at &lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.24.0.Final.html"&gt;this page&lt;/a&gt;. Some highlights are below.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="quarkus-tools"&gt;&lt;a class="anchor" href="#quarkus-tools"&gt;&lt;/a&gt;Quarkus Tools&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="improvement-to-the-new-quarkus-project-wizard"&gt;&lt;a class="anchor" href="#improvement-to-the-new-quarkus-project-wizard"&gt;&lt;/a&gt;Improvement to the new Quarkus project wizard&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When the new Quarkus project wizard was initially design, there were a few Quarkus extensions so it was not difficult to find one from the total list. Now that the Quarkus ecosystem is growing fast, it was difficult even of the extensions were grouped into categories.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In order to cope with this issue, the extensions and categories are now displayed in a tree (first level is categories, second level is extensions).&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This new tree can now be filtered through a text field. If user enter some characters, only extensions matching this filter will be displayed in the tree.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/quarkus/images/quarkus45.gif" alt="quarkus45" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="hibernate-tools"&gt;&lt;a class="anchor" href="#hibernate-tools"&gt;&lt;/a&gt;Hibernate Tools&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="hibernate-runtime-provider-updates"&gt;&lt;a class="anchor" href="#hibernate-runtime-provider-updates"&gt;&lt;/a&gt;Hibernate Runtime Provider Updates&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A number of additions and updates have been performed on the available Hibernate runtime providers.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="runtime-provider-updates"&gt;&lt;a class="anchor" href="#runtime-provider-updates"&gt;&lt;/a&gt;Runtime Provider Updates&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 6.0 runtime provider (Preview) now incorporates Hibernate Core version 6.0.2.Final and Hibernate Tools version 6.0.2.Final.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 5.6 runtime provider now incorporates Hibernate Core version 5.6.9.Final and Hibernate Tools version 5.6.9.Final.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 5.3 runtime provider now incorporates Hibernate Core version 5.3.27.Final and Hibernate Tools version 5.3.27.Final.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="and-more"&gt;&lt;a class="anchor" href="#and-more"&gt;&lt;/a&gt;And more…​&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;You can find more noteworthy updates in on &lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.24.0.Final.html"&gt;this page&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Enjoy!&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Jeff Maury&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;</content><summary>Happy to announce 4.24.0.Final build for Eclipse 2022-06. Downloads available at JBoss Tools 4.24.0.Final. What is New? Full info is at this page. Some highlights are below. Quarkus Tools Improvement to the new Quarkus project wizard When the new Quarkus project wizard was initially design, there were a few Quarkus extensions so it was not difficult to find one from the total list. Now that the Quarkus ecosystem is growing fast, it was difficult even of the extensions were grouped into categories. In order to cope with this issue, the extensions and categories are now displayed in a tree (first level is categories, second level is extensions). This new tree...</summary><dc:creator>jeffmaury</dc:creator><dc:date>2022-07-04T00:00:00Z</dc:date></entry><entry><title>Red Hat Developer roundup: Best of June 2022</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/30/red-hat-developer-roundup-best-june-2022" /><author><name>Josh Fruhlinger</name></author><id>79a05456-6c28-4b45-a502-e09bbf2fab00</id><updated>2022-06-30T07:00:00Z</updated><published>2022-06-30T07:00:00Z</published><summary type="html">&lt;p&gt;Welcome to our monthly recap of the articles we published in June! This month, we rolled out an armada of articles to help you build—and lock down—code on the platforms you trust. Here are the June highlights.&lt;/p&gt; &lt;h2&gt;Security for Kubernetes, Go, and beyond&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; is increasingly central to modern distributed and &lt;a href="https://developers.redhat.com/topics/containers"&gt;containerized&lt;/a&gt; development today, but it's a complex system that's difficult to secure. Ajmal Kohgadai and Andy Oram delivered a three-part series on Kubernetes security to help put your mind at ease:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/13/kubernetes-security-risks-keep-developers-night"&gt;Kubernetes security risks that keep developers up at night&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/14/4-tips-achieving-better-security-kubernetes"&gt;4 tips for achieving better security on Kubernetes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/15/best-practices-successful-devsecops"&gt;Best practices for successful DevSecOps&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Andy also rounded things out with a tour of &lt;a href="https://developers.redhat.com/articles/2022/06/20/8-open-source-kubernetes-security-tools"&gt;8 great open source Kubernetes security tools&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Red Hat Developer also took a look at security issues in the &lt;a href="http://Go"&gt;Go&lt;/a&gt; language. We provided a &lt;a href="https://developers.redhat.com/articles/2022/06/28/cross-site-scripting-explanation-and-prevention-go"&gt;primer on cross-site scripting&lt;/a&gt; that explained how you can prevent this type of attack when building applications in Go; we also showed you how to make sure your Go applications on RHEL &lt;a href="https://developers.redhat.com/articles/2022/05/31/your-go-application-fips-compliant"&gt;comply with the FIPS standard&lt;/a&gt; mandated for U.S. government contractors.&lt;/p&gt; &lt;p&gt;And finally, if you're dealing with good old-fashioned &lt;a href="https://developers.redhat.com/topics/c/"&gt;C&lt;/a&gt;, Serge Guelton and Siddhesh Poyarekar taught you how to &lt;a href="https://developers.redhat.com/articles/2022/06/02/use-compiler-flags-stack-protection-gcc-and-clang"&gt;use compiler flags to protect against stack-smashing attacks&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Dig deep into internals&lt;/h2&gt; &lt;p&gt;Some of our most popular articles of this month really got into the nitty-gritty of code execution, compilation, and performance monitoring. Thanks to Red Hat Developer's experts, you learned how to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Use the GNU Debugger to &lt;a href="https://developers.redhat.com/articles/2022/06/07/how-debug-stack-frames-and-recursion-gdb"&gt;debug stack frames and recursion&lt;/a&gt;, a common cause of programming errors.&lt;/li&gt; &lt;li&gt;Use the Bunsen test suite to track down &lt;a href="https://developers.redhat.com/articles/2022/06/09/detecting-nondeterministic-test-cases-bunsen"&gt;"flaky" tests that produce different outcomes&lt;/a&gt; when run repeatedly.&lt;/li&gt; &lt;li&gt;Monitor the performance of &lt;a href="https://developers.redhat.com/articles/2022/06/22/measuring-bpf-performance-tips-tricks-and-best-practices"&gt;BPF programs&lt;/a&gt; that themselves inspect other system activity.&lt;/li&gt; &lt;li&gt;Reveal potential performance problems, down to individual lines of code, with &lt;a href="https://developers.redhat.com/articles/2022/06/27/use-systemtap-example-script-trace-kernel-code-operation"&gt;SystemTap and one of its prewritten example scripts&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;SaaS architectures&lt;/h2&gt; &lt;p&gt;We continued a series that we &lt;a href="https://developers.redhat.com/articles/2022/05/18/saas-architecture-checklist-kubernetes"&gt;began in May&lt;/a&gt; about building and deploying Software as a service (SaaS) applications, and these also proved to be a big hit with readers. This month, you learned how to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Convert an &lt;a href="articles/2022/06/16/how-convert-web-application-software-service"&gt;existing web application into a SaaS service&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Develop a &lt;a href="https://developers.redhat.com/articles/2022/06/23/multi-cloud-storage-strategies-saas-applications"&gt;multi-cloud storage strategy&lt;/a&gt; to accommodate different environments where your SaaS service might be deployed.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Check out these articles and be on the lookout for future installments.&lt;/p&gt; &lt;h2&gt;Instrument containerized Java applications with Cryostat&lt;/h2&gt; &lt;p&gt;You probably have used Java Flight Recorder, an excellent tool for analyzing and understanding &lt;a href="https://developers.redhat.com/topics/java"&gt;Java&lt;/a&gt; workloads. It comes in handy during development or while workloads run in production. Cryostat takes that further by bringing the same functionality to containers and Kubernetes. You can check out our &lt;a href=""&gt;roundup of what's new in Cryostat 2.1&lt;/a&gt;, the latest version of the tool. You can also learn how to &lt;a href="https://developers.redhat.com/articles/2022/06/20/install-cryostat-new-helm-chart"&gt;install Cryostat using a Helm chart&lt;/a&gt;, which is suitable for demo purposes and simpler than using the Cryostat Operator.&lt;/p&gt; &lt;h2&gt;June 2022 on Red Hat Developer&lt;/h2&gt; &lt;p&gt;Here's the full lineup of articles published on Red Hat Developer so far this month:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/05/31/integrate-spring-boot-application-red-hat-data-grid"&gt;Integrate a Spring Boot application with Red Hat Data Grid&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/05/31/your-go-application-fips-compliant"&gt;Is your Go application FIPS compliant?&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/01/open-source-edge-detection-opencv-and-pachyderm"&gt;Open source edge detection with OpenCV and Pachyderm&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/01/join-red-hat-team-openjs-world-2022"&gt;Join the Red Hat team at OpenJS World 2022&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/02/how-create-kafka-consumers-and-producers-java"&gt;How to create Kafka consumers and producers in Java&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/02/use-compiler-flags-stack-protection-gcc-and-clang"&gt;Use compiler flags for stack protection in GCC and Clang&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/06/whats-new-version-27-red-hat-build-quarkus"&gt;What's new in version 2.7 of the Red Hat build of Quarkus&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/06/kafka-monthly-digest-may-2022"&gt;Kafka Monthly Digest: May 2022&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/07/thousands-pypi-and-rubygems-rpms-now-available-rhel-9"&gt;Thousands of PyPI and RubyGems RPMs now available for RHEL 9&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/07/how-debug-stack-frames-and-recursion-gdb"&gt;How to debug stack frames and recursion in GDB&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/08/eliminate-downtime-during-openshift-rolling-updates"&gt;Eliminate downtime during OpenShift rolling updates&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/08/9-awesome-updates-cryostat-21"&gt;9 awesome updates in Cryostat 2.1&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/09/detecting-nondeterministic-test-cases-bunsen"&gt;Detecting nondeterministic test cases with Bunsen&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/09/get-started-red-hat-openshift-connectors"&gt;Get started with Red Hat OpenShift Connectors&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/13/quick-way-translate-physical-addresses-virtual-ones"&gt;A quick way to translate physical addresses into virtual ones&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/13/kubernetes-security-risks-keep-developers-night"&gt;Kubernetes security risks that keep developers up at night&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/13/use-openvino-convert-speech-text"&gt;Use OpenVINO to convert speech to text&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/14/4-tips-achieving-better-security-kubernetes"&gt;4 tips for achieving better security on Kubernetes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/15/openssl-30-dealing-turkish-locale-bug"&gt;OpenSSL 3.0: Dealing with a Turkish locale bug&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/15/best-practices-successful-devsecops"&gt;Best practices for successful DevSecOps&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/16/learn-about-openshift-command-line-tools"&gt;Learn about OpenShift command-line tools&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/16/how-convert-web-application-software-service"&gt;How to convert a web application to Software-as-a-Service&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/20/install-cryostat-new-helm-chart"&gt;Install Cryostat with the new Helm chart&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/20/8-open-source-kubernetes-security-tools"&gt;8 open source Kubernetes security tools&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/21/distributed-tracing-opentelemetry-knative-and-quarkus"&gt;Distributed tracing with OpenTelemetry, Knative, and Quarkus&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/22/measuring-bpf-performance-tips-tricks-and-best-practices"&gt;Measuring BPF performance: Tips, tricks, and best practices&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/23/multi-cloud-storage-strategies-saas-applications"&gt;Multi-cloud storage strategies for SaaS applications&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/23/gpu-enablement-microshift"&gt;GPU enablement on MicroShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/24/road-jboss-eap-8"&gt;The road to JBoss EAP 8&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/27/use-systemtap-example-script-trace-kernel-code-operation"&gt;Use a SystemTap example script to trace kernel code operation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/28/cross-site-scripting-explanation-and-prevention-go"&gt;Cross-site scripting: Explanation and prevention with Go&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/29/how-add-libraries-nodejs-container-s2i"&gt;How to add libraries to a Node.js container with S2I&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/30/red-hat-developer-roundup-best-june-2022" title="Red Hat Developer roundup: Best of June 2022"&gt;Red Hat Developer roundup: Best of June 2022&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Josh Fruhlinger</dc:creator><dc:date>2022-06-30T07:00:00Z</dc:date></entry><entry><title type="html">This Week in JBoss - June 30th 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-06-30.html" /><category term="quarkus" /><category term="java" /><category term="kubernetes" /><category term="openshift" /><category term="security" /><category term="xss" /><category term="golang" /><category term="go" /><category term="javascript" /><category term="graphql" /><author><name>Stefan Sitani</name><uri>https://www.jboss.org/people/stefan-sitani</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-06-30.html</id><updated>2022-06-30T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, java, kubernetes, openshift, security, xss, golang, go, javascript, graphql"&gt; &lt;h1&gt;This Week in JBoss - June 30th 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Hello and welcome to JBoss Editorial June 30th edition! We are nearing the end of the second week of summer, and most of us are already looking forward to our vacation plans. And while for some the next 2 months will be a time to relax, slow down, and take things a little easy, progress and innovation never really stop! So for those of you interested in the latest and the greatest that your favorite project have to offer, here are this week’s highlights from around the JBoss community.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_releases_releases_releases"&gt;Releases, releases, releases!&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Here are the releases from the JBoss Community for this edition:&lt;/p&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://camel.apache.org/blog/2022/06/camel-quarkus-release-2.10.0/"&gt;Camel Quarkus 2.10.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://debezium.io/blog/2022/06/21/debezium-1-9-4-final-released/"&gt;Debezium 1.9.4.Final&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org/2022/06/keycloak-1802-released"&gt;Keycloak 18.0.2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/06/kogito-1-23-0-released.html"&gt;Kogito 1.23.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/smallrye/smallrye-mutiny/releases/tag/1.6.0"&gt;Mutiny 1.6.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-10-0-final-released/"&gt;Quarkus 2.10.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_articles_blogs"&gt;Articles &amp;#38; Blogs&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="sect2"&gt; &lt;h3 id="_how_to_convert_a_web_application_to_software_as_a_service"&gt;How to convert a web application to Software-as-a-Service&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/16/how-convert-web-application-software-service#"&gt;How to convert a web application to Software-as-a-Service&lt;/a&gt; by Bob Reselman&lt;/p&gt; &lt;p&gt;Bob Reselman delves into the "brownfield" approach to redeveloping your web application into a SaaS platform. Starting off with a well-laid out example business scenario, Bob walks you through the key steps of the process from analyzing your business logic patterns, separating configuration from code, picking an appropriate service architecture, to leveraging the benefits offered by containerization and Kubernetes to ensure that you’ll always be able to scale your services to match the growth of your business.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_multi_cloud_storage_strategies_for_saas_applications"&gt;Multi-cloud storage strategies for SaaS applications&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/23/multi-cloud-storage-strategies-saas-applications#"&gt;Multi-cloud storage strategies for SaaS applications&lt;/a&gt; by Michael Hrivnak&lt;/p&gt; &lt;p&gt;In the fourth entry to the ongoing &lt;a href="https://developers.redhat.com/articles/2022/05/18/saas-architecture-checklist-kubernetes"&gt;&lt;em&gt;SaaS architecture checklist&lt;/em&gt;&lt;/a&gt; blog series Michael Hrivnak compares software-defined storage (SDS) technologies that help developers create optimized data storage solutions for use in multi-tenant cloud environments. The first part of Michael’s article deals with the broader technical consideration of how SDS can help developers minimize platform-specific development work, followed by an overview of Red Hat’s current cloud storage technology offerings. In the latter section, Michael provides some insight into combining these offerings to create solutions that provide customers with self-scaling, self-managed, low-latency data storage capabilities.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_cross_site_scripting_explanation_and_prevention_with_go"&gt;Cross-site scripting: Explanation and prevention with Go&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/28/cross-site-scripting-explanation-and-prevention-go#"&gt;Cross-site scripting: Explanation and prevention with Go&lt;/a&gt; by Sandipan Roy&lt;/p&gt; &lt;p&gt;Cross-site scripting (XSS) attacks have recently become a topic of interest among application security experts in the cloud native developer community. In his tutorial, Sandipan breaks down the mechanism of executing an XSS attack using malicious JavaScript elements and follows up by outlining 3 strategies for coding in Go that you can use to protect your applications against different types of XSS attacks (Sandipan mentions Stored, Reflected and DOM-based XSS attacks). The tutorial is richly supplemented by code examples and plenty of additional information context. Even though this article is a little outside our usual focus area, it is definitely worth a read, especially for those of you interested in buffing up your application security knowledge.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_how_to_build_graphql_applications_with_quarkus"&gt;How to build GraphQL applications with Quarkus&lt;/h3&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/soa-cloud/quarkus/how-to-build-graphql-applications-with-quarkus/"&gt;How to build GraphQL applications with Quarkus&lt;/a&gt; by Francesco Marchioni&lt;/p&gt; &lt;p&gt;In a follow-up to his &lt;a href="http://www.mastertheboss.com/eclipse/eclipse-microservices/getting-started-with-graphql-using-java-applications/"&gt;earlier article&lt;/a&gt; about GraphQL on WildFly, Francesco is back with another tutorial, this time about GraphQL and Quarkus. The article opens with a brief discussion of the advantages that GraphQL’s schema based data access model has over REST APIs. Francesco then moves on to showing how you can use &lt;a href="https://code.quarkus.io"&gt;code.quarkus.io&lt;/a&gt; to create a Quarkus application that supports GraphQL using the MicroProfile-compliant SmallRye GraphQL extensions. The test of the tutorial is a step-by-step guide to writing the service class of the application and a GraphQL API class that handles the Query and Mutation operations supported by GraphQL. At this point, Francesco offers a bit of comparison between the different ways that data access operations work in GraphQL as opposed to REST. The tutorial ends with sections detailing how you can test your applications using either the GraphQL UI provided by the extension, or the SmallRye MicroProfile GraphQL client API. In a manner typical of most of Francesco’s tutorials, this one also contains a link to a repository with the code for this example project. And those of you interested in learning more about GraphQL in Quarkus, check out &lt;em&gt;Quarkus Insights&lt;/em&gt; episode #93. You can find the link to it in the &lt;em&gt;Videos&lt;/em&gt; section of this week’s editorial.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_videos"&gt;Videos&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;This week there was plenty of fresh content to choose from, so please enjoy some of my top video picks:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/qqztCp5Bvbg"&gt;Quarkus Insights #94: Scientific Games meets Quarkus&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/PHWOzzusfrY"&gt;Quarkus Insights #93: The Latest with GraphQL and Quarkus&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/w5SBQpAQ8m8"&gt;Using Minecraft as an Observability Client: A demo by Holly Cummins&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/00g-gBIYpsU"&gt;Quinoa: A modern Quarkus UI with no hassles: DevNation talk by Andy Damevin&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/LhTR_ECSaAo"&gt;Debugging natively compiled Java code with NativeJDB: A demo by Ansu Varghese&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/4HI8bVd8JFc"&gt;JNation.PT 2022: All Quarkus Track Sessions Recorded&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt;&lt;em&gt;That’s all for today! Please join us again in two weeks for another round of our JBoss editorial! Stay safe and enjoy your summer vacation!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/stefan-sitani.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Stefan Sitani&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Stefan Sitani</dc:creator></entry></feed>
