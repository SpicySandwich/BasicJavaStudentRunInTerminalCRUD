<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>What qualifies for Red Hat Developer Subscription for Teams?</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/06/what-qualifies-red-hat-developer-subscription-teams" /><author><name>Josh Swanson, Brian Gollaher</name></author><id>d60e8bf3-bc55-40a1-9b6c-cb96c30b3df5</id><updated>2022-07-06T07:00:00Z</updated><published>2022-07-06T07:00:00Z</published><summary type="html">&lt;p&gt;Recently, Red Hat &lt;a href="https://developers.redhat.com/articles/2022/05/10/access-rhel-developer-teams-subscription"&gt;relaunched&lt;/a&gt; the Developer Subscription for Teams, enabling organizations &lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;already running other Red Hat technologies to&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; access &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; for their development activities without friction. In this article, we clarify what Red Hat defines as development activities and highlight some exciting use cases for the Developer Subscription for Teams.&lt;/p&gt; &lt;h2&gt;What activities are considered development use?&lt;/h2&gt; &lt;p&gt;Figure 1 calls out the delimitation between development and production activities according to &lt;a href="https://www.redhat.com/en/about/agreements"&gt;Appendix 1&lt;/a&gt; of the Red Hat license agreement. To begin breaking this down, let’s start at the far left end, where systems would leverage the Developer Subscription for Teams.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Development-Use-Cases_diagram.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/Development-Use-Cases_diagram.png?itok=VAp0P1Op" width="1440" height="422" alt="Development activities grouped under RHEL Developer for Teams and production activities grouped under RHEL." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: How activities are categorized for development and production according to the Red Hat Enterprise Agreements.&lt;/figcaption&gt; &lt;/figure&gt; &lt;h2&gt;An example application&lt;/h2&gt; &lt;p&gt;Let’s consider a fairly simple yet mission-critical application: a tax calculator. When most businesses run transactions for goods and services, the appropriate taxes must be calculated and added to the total purchase price. Our example application consists of three parts:&lt;/p&gt; &lt;ul&gt; &lt;li aria-level="1"&gt;A database that stores the appropriate tax information and rates.&lt;/li&gt; &lt;li aria-level="1"&gt;A middle tier that retrieves tax information from the database and performs calculations.&lt;/li&gt; &lt;li aria-level="1"&gt;A front-end system running a RESTful API that’s used to interact with the application.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These three tiers come together to form our tax application. They will be the basis for considering how the Developer Subscription for Teams enables the rapid development, testing, and deployment of this application. Now we’ll walk through each phase, as illustrated in Figure 1.&lt;/p&gt; &lt;h2&gt;Software design and coding&lt;/h2&gt; &lt;p&gt;When developing, updating, or maintaining this tax application, there are often design phases meant to outline the intended end state: functionality, architecture, features, and components. Once the design is accepted, then the actual work of writing the code begins. The systems used for designing a new application or upgrading an existing one with new features, overhauling legacy code, squashing bugs, etc., would all be covered by the Developer Subscription for Teams.&lt;/p&gt; &lt;h2&gt;Building&lt;/h2&gt; &lt;p&gt;Once the code for our tax application is written, we might need to build the application, which means pulling in dependencies, setting appropriate values, and outputting them into a form that can easily be deployed. We might also need to build multiple deployment packages that can be deployed across multiple systems in multiple environments and compute spaces, such as a cloud provider or on-premise datacenter.&lt;/p&gt; &lt;p&gt;Since this action might require more computational power than what a standard workstation provides, it makes sense to leverage the capabilities of a hyperscaler. The systems we use to build the application would also qualify for the Developer Subscription for Teams.&lt;/p&gt; &lt;h2&gt;Unit testing&lt;/h2&gt; &lt;p&gt;Our three-tier tax application, composed of three parts (a database, a middle tier, and a front-end API), can be broken apart and tested individually, allowing for more thorough testing of the components and more targeted testing.&lt;/p&gt; &lt;p&gt;Our database can be loaded with the appropriate tax information and then put through a schema update test to ensure tax information can be updated without application downtime.&lt;/p&gt; &lt;p&gt;Second, our middle tier can be put through a load test to demonstrate expected response times and validate that multiple calculations can be run simultaneously without causing calculation collisions.&lt;/p&gt; &lt;p&gt;Finally, our front-end API’s role-based access control (RBAC) functionality can be tested to ensure only requests coming from the appropriate systems are accepted and sent to be processed by the application, and that the API returns the results in a data format that other applications can easily consume.&lt;/p&gt; &lt;p&gt;What’s unique about this specific step in the software development life cycle is that the number of systems needed to properly test and validate each unit of the application increases almost exponentially. A database system is necessary, and we also need a system to run some test transactions via a connection to the database while another system is running a schema update. Our middle-tier system needs multiple other systems connected and requesting taxes be calculated while being able to reference an external source of controlled data to ensure calculations are accurate. Finally, our API needs to be receiving requests from different sources, some of which are allowed via RBAC rules and some that are not, while being able to return consumable data to those authorized sources.&lt;/p&gt; &lt;h2&gt;System integration and integration testing&lt;/h2&gt; &lt;p&gt;At this step in the software development life cycle, we start to put the puzzle pieces of our application landscape together. Here, we’ll combine our example tax application with our existing point-of-sale application, our ledger application, our inventory tracking application, and so on. All these applications must work together successfully for our customers to be able to make a purchase, so testing and validation of the integration of these various applications is crucial.&lt;/p&gt; &lt;p&gt;First, we can spin up the other applications and ensure they’re communicating with each other; then, we can add in our example tax application. Once the appropriate API endpoints are specified, RBAC rules are written, and network communication is validated, we can test running real-world transactions through our system and look for any piece of the puzzle that isn’t working or is blocking a successful purchase. We can also use real-world data here to ensure our test environment completes the purchase as expected.&lt;/p&gt; &lt;h2&gt;Pre-prod testing&lt;/h2&gt; &lt;p&gt;Here, we develop, test, and practice the steps needed to safely introduce our new example tax application to our production environment in a space that closely resembles it. We’ll walk through identifying what outages are required and what impact that will have on our business, as well as clearly documenting any steps that need to be taken by teams to deploy our new tax application successfully. These steps can be tested multiple times for training and practice purposes in this environment without impacting production.&lt;/p&gt; &lt;p&gt;An environment such as this is often a scaled-down version of production that is constantly running, and has multiple teams that can access and leverage it for various activities. Again, the Developer Subscription for Teams covers this environment, removing the subscription barrier to entry and having an appropriate place to test the introduction of our tax application to production.&lt;/p&gt; &lt;h2&gt;Push to production&lt;/h2&gt; &lt;p&gt;Here’s where we cross the bridge from the Developer Subscription for Teams into “production” Red Hat Enterprise Linux subscriptions. Let’s say our organization uses a combination of continuous integration/continuous delivery (CI/CD) pipelines and &lt;a href="https://developers.redhat.com/articles/2022/05/26/whats-new-ansible-automation-platform-22"&gt;Red Hat Ansible Automation Platform&lt;/a&gt; to deploy our applications in production from our code repository. The two are closely integrated to perform the steps we identified during testing in our pre-prod environment.&lt;/p&gt; &lt;p&gt;Our Red Hat Ansible Automation Platform subscriptions would cover the automation piece of the push-to-production story, and production. Red Hat Enterprise Linux subscriptions would cover the systems running our code repository and CI/CD pipelines, because our production code is flowing through them. Like the Developer Subscription for Teams, most production Red Hat Enterprise Linux subscriptions are cloud-eligible, meaning that these systems can run on-premise or off, and in the case of the CI/CD pipelines, can be spun up in a cloud on-demand to support our deployment activities.&lt;/p&gt; &lt;h2&gt;Monitor&lt;/h2&gt; &lt;p&gt;These systems are the watchers on the (proverbial) wall: constantly checking in on our various production and pre-production systems, ensuring they’re up and running as expected. Should a system go down or become unresponsive, these systems are responsible for identifying the downed system(s), attempting to recover services automatically, and, if that fails, reaching out for human intervention to restore functionality via various communication systems such as email or chat notifications. The systems watching for outages, attempting automatic recovery, and transporting outage notifications would consume production Red Hat Enterprise Linux subscriptions.&lt;/p&gt; &lt;h2&gt;Update and maintain&lt;/h2&gt; &lt;p&gt;The last block called out in Figure 1 encompasses systems used to keep our production environment running and healthy. These could be systems dedicated to storing updates for our systems (such as Red Hat Satellite) as well as systems used to apply these updates across our landscape (such as Red Hat Ansible Automation Platform). Other systems used to support these actions, such as bastion servers, proxies for downloading updates, and systems hosting firmware updates or other update packages, would also fall into this category, leveraging a production Red Hat Enterprise Linux subscription.&lt;/p&gt; &lt;p&gt;For a more condensed view of various systems and their respective subscription, here’s a quick reference table:&lt;/p&gt; &lt;div&gt; &lt;table cellspacing="0"&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;&lt;strong&gt;System purpose&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;strong&gt;Subscription type&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Code validation and testing system&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Developer Subscription for Teams&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Load generating server for testing&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Developer Subscription for Teams&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Testing database with production data&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Developer Subscription for Teams&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Build server that creates app RPMs&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Developer Subscription for Teams&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;API endpoint testing system&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Developer Subscription for Teams&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Outage email server&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Production subscription&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Code repository&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Production subscription&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;CI/CD pipeline systems&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Production subscription&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Firmware download proxy&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;Production subscription&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The Developer Subscription for Teams is a powerful option for software development and testing in an organization, allowing for easy consumption of Red Hat Enterprise Linux in the spirit of building and testing new and existing applications.&lt;/p&gt; &lt;p&gt;If you’re interested in the Developer Subscription for Teams, &lt;a href="https://www.redhat.com/en/contact?sc_cid=7013a000003163VAAQ"&gt;reach out to a Red Hatter today&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/06/what-qualifies-red-hat-developer-subscription-teams" title="What qualifies for Red Hat Developer Subscription for Teams?"&gt;What qualifies for Red Hat Developer Subscription for Teams?&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Josh Swanson, Brian Gollaher</dc:creator><dc:date>2022-07-06T07:00:00Z</dc:date></entry><entry><title>Write a SystemTap script to trace code execution on Linux</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/05/write-systemtap-script-trace-code-execution-linux" /><author><name>William Cohen</name></author><id>6519b4dd-d8da-4ff5-a3b5-86e01a7fc42d</id><updated>2022-07-05T07:00:00Z</updated><published>2022-07-05T07:00:00Z</published><summary type="html">&lt;p&gt;This is the second article in a two-part series about &lt;a href="https://sourceware.org/systemtap/"&gt;SystemTap&lt;/a&gt;, a tool for adding instrumentation to &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; systems to better understand the behavior of the kernel and of userspace applications or libraries. The &lt;a href="https://developers.redhat.com/articles/2022/06/27/use-systemtap-example-script-trace-kernel-code-operation"&gt;first article&lt;/a&gt; used an existing example script called &lt;code&gt;linetimes.stp&lt;/code&gt; to uncover a possible performance problem.&lt;/p&gt; &lt;p&gt;Now we'll show how SystemTap determines where to place the instrumentation, a few common SystemTap coding techniques, how the &lt;code&gt;linetimes.stp&lt;/code&gt; script was created, and some issues encountered when implementing the script.&lt;/p&gt; &lt;h2&gt;How does linetimes.stp work?&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://developers.redhat.com/blog/2021/01/07/debuginfo-is-not-just-for-debugging-programs"&gt;debugging information&lt;/a&gt; produced by the compiler contains several different pieces of information, including the regions occupied by functions and output mapping machine instructions back to the files and lines of source code.&lt;/p&gt; &lt;p&gt;Multiple machine-language instructions can be associated with a particular line of code. The compiler marks the appropriate instruction that represents the start of a statement in the line information. The script probes each statement start using the following statement:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;probe $1.statement(@2 "@*:*")&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;$1&lt;/code&gt; will be filled in with the first argument passed to the script, indicating what binary (the kernel, a kernel module, or a userspace application) is being instrumented. The &lt;code&gt;@2&lt;/code&gt; will be filled in by the second argument passed to the script: the name of the function being instrumented. The at symbol (&lt;code&gt;@&lt;/code&gt;) indicates that the second argument should be converted to a string. The &lt;code&gt;$1&lt;/code&gt; argument requires no conversion and remains as is.&lt;/p&gt; &lt;p&gt;The string &lt;code&gt;@*:*&lt;/code&gt; specifies a wildcard probe, requesting all filenames through the first asterisk and all line numbers through the second asterisk.&lt;/p&gt; &lt;p&gt;Now that we have the probes, the next step is to create a probe handler that computes the times between the successive probes, accumulates those times, and tracks the control flow through the program. The script needs some state information stored in global associative arrays. The elapsed times (in an array called &lt;code&gt;times&lt;/code&gt;) and last probe point seen (in an array called &lt;code&gt;last_pp&lt;/code&gt;) need to be tracked on a per-thread basis. The probe handler uses the thread ID, &lt;code&gt;tid()&lt;/code&gt;, to access those associative arrays and keep information about each thread distinct.&lt;/p&gt; &lt;p&gt;By default, if there is no entry in the associative array for a key, the value 0 is returned when the program tries to read the entry. To avoid computing a negative elapsed time by subtracting the current time from 0, you need to check that &lt;code&gt;times[pid()]&lt;/code&gt; has a non-zero value. A non-zero time value indicates that an earlier probe on the thread was triggered, so there is information about the time in &lt;code&gt;times&lt;/code&gt; and the previous probe point in &lt;code&gt;last_pp&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The body of the &lt;code&gt;if&lt;/code&gt; statement in the following probe handler computes the elapsed time, &lt;code&gt;e&lt;/code&gt;. The times are accumulated in the &lt;code&gt;region&lt;/code&gt; statistical associative array with the &lt;code&gt;&lt;&lt;&lt;&lt;/code&gt; operator. The probe point stored in &lt;code&gt;last_pp&lt;/code&gt; is used as a key to group together times with the same starting line.&lt;/p&gt; &lt;p&gt;The last statement in the body of the &lt;code&gt;if&lt;/code&gt; statement records the path from the previous probe location (&lt;code&gt;last_pp[tid()]&lt;/code&gt;) to the current probe location (&lt;code&gt;pp()&lt;/code&gt;) in the &lt;code&gt;cfg&lt;/code&gt; associative array. Following the &lt;code&gt;if&lt;/code&gt; statement, the probe handler ends by updating the &lt;code&gt;times&lt;/code&gt; and &lt;code&gt;last_pp&lt;/code&gt; entries for the thread:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;global times, last_pp, region, cfg probe $1.statement(@2 "@*:*") { t = gettimeofday_us() s = times[tid()] if (s) { e = t - s region[last_pp[tid()]] &lt;&lt;&lt; e cfg[last_pp[tid()], pp()] &lt;&lt;&lt; 1 } times[tid()] = t last_pp[tid()] = pp() }&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Properly handling function returns&lt;/h3&gt; &lt;p&gt;One situation the script needs to address is leaving the function via a return and then having the function called again. With just the probe shown previously, the script would include the time between the last statement before the function return and the first statement executed on the next call to the function. To avoid this error, the script needs to have a probe similar to the previous one, but on the function return. The main difference between the two is that the return probe removes the &lt;code&gt;times&lt;/code&gt; and &lt;code&gt;last_pp&lt;/code&gt; entries from the associative arrays to avoid computing the unwanted interval.&lt;/p&gt; &lt;p&gt;This design results in the following probe. As before, &lt;code&gt;$1&lt;/code&gt; indicates whether the instrumented binary is the kernel, a kernel module, or a userspace binary, and &lt;code&gt;@2&lt;/code&gt; is the function name:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;probe $1.function(@2).return { t = gettimeofday_us() s = times[tid()] if (s) { e = t - s region[last_pp[tid()]] &lt;&lt;&lt; e cfg[last_pp[tid()], pp()] &lt;&lt;&lt; 1 } delete times[tid()] delete last_pp[tid()] }&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Counting the function entries&lt;/h3&gt; &lt;p&gt;To gauge the relative frequency of paths through the code, one would like to know the number of times the function is called. This information is recorded in a global variable (&lt;code&gt;calls&lt;/code&gt;) and the following one-line probe that counts each time the function is entered. This probe uses the statistics operator (&lt;code&gt;&lt;&lt;&lt;&lt;/code&gt;) for efficiency, because multiple probes can operate concurrently without locking:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;global calls probe $1.function(@2).call { calls &lt;&lt;&lt; 1 }&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Generating the results&lt;/h3&gt; &lt;p&gt;One last probe is needed to generate the output when the script exits. This task is implemented with an end probe. The output is generated using &lt;code&gt;printf&lt;/code&gt; statements. The SystemTap &lt;code&gt;printf&lt;/code&gt; allows formatting with field width and justification. The &lt;code&gt;%-58s&lt;/code&gt; in the third &lt;code&gt;printf&lt;/code&gt; left-justifies the output of a string printed in a 58-character wide field, and the following two &lt;code&gt;%10d&lt;/code&gt; entries format two right-justified decimal numbers in 10-character wide fields.&lt;/p&gt; &lt;p&gt;There are two sections of code. The first section prints out the headers for the region information, then uses a &lt;code&gt;foreach&lt;/code&gt; loop to print a line with the statistical average and maximum time recorded for each region. The loop variable is &lt;code&gt;p&lt;/code&gt; and the &lt;code&gt;+&lt;/code&gt; sign indicates that the loop should sort the values of &lt;code&gt;p&lt;/code&gt; in ascending order. In this case, output is in the same order as the lines in the source code.&lt;/p&gt; &lt;p&gt;The second section prints the control flow graph information, which is implemented with nested &lt;code&gt;foreach&lt;/code&gt; loops. The outer loop prints each line executed, and the inner loop prints out all the lines that were executed immediately following it, with a count of the executions:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;probe end { printf("\n%s %s call count: %d\n", @1, @2, @count(calls)); printf("\n%-58s %10s %10s\n", "region", "avg(us)", "max(us)"); foreach (p+ in region) { printf("%-58s %10d %10d\n", p, @avg(region[p]), @max(region[p])); } printf("\n\ncontrol flow graph information\n") printf("from\n\tto\n=======================\n") foreach ([src+] in region) { printf("%-s\n", src) foreach ([s,dest+] in cfg[src,*]) { # slice for all dest's printf("\t%-s %d\n", dest, @count(cfg[src,dest])); } } }&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Putting the script together&lt;/h3&gt; &lt;p&gt;All the previous pieces of code have been assembled into a single file in &lt;code&gt;/usr/share/systemtap/examples/process/linetimes.stp&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="none"&gt;#! /usr/bin/env stap # # Copyright (C) 2010-2015 Red Hat, Inc. # Written by William Cohen &lt;wcohen@redhat.com&gt; # # The linetimes.stp script takes two arguments: where to find the function # and the function name. linetimes.stp will instrument each line in the # function. It will print out the number of times that the function is # called, a table with the average and maximum time each line takes, # and control flow information when the script exits. # # For example all the lines of the do_unlinkat function: # # stap linetimes.stp kernel do_unlinkat global calls, times, last_pp, region, cfg probe $1.function(@2).call { calls &lt;&lt;&lt; 1 } probe $1.function(@2).return { t = gettimeofday_us() s = times[tid()] if (s) { e = t - s region[last_pp[tid()]] &lt;&lt;&lt; e cfg[last_pp[tid()], pp()] &lt;&lt;&lt; 1 } delete times[tid()] delete last_pp[tid()] } probe $1.statement(@2 "@*:*") { t = gettimeofday_us() s = times[tid()] if (s) { e = t - s region[last_pp[tid()]] &lt;&lt;&lt; e cfg[last_pp[tid()], pp()] &lt;&lt;&lt; 1 } times[tid()] = t last_pp[tid()] = pp() } probe end { printf("\n%s %s call count: %d\n", @1, @2, @count(calls)); printf("\n%-58s %10s %10s\n", "region", "avg(us)", "max(us)"); foreach (p+ in region) { printf("%-58s %10d %10d\n", p, @avg(region[p]), @max(region[p])); } printf("\n\ncontrol flow graph information\n") printf("from\n\tto\n=======================\n") foreach ([src+] in region) { printf("%-s\n", src) foreach ([s,dest+] in cfg[src,*]) { # slice for all dest's printf("\t%-s %d\n", dest, @count(cfg[src,dest])); } } }&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Limitations&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;linetimes.stp&lt;/code&gt; script is useful, but suffers from several limitations:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The measurements include overhead from the probe handlers. The line of code being measured might only be a few instructions, whereas the probe hander's overhead is significantly more. The script is therefore most useful when a line of code calls a function and you are trying to determine which calls are slower and faster in the function.&lt;/li&gt; &lt;li&gt;The script can't monitor inline functions, because the probes for function entry (&lt;code&gt;probe $1.function(@2).call&lt;/code&gt;) and return (&lt;code&gt;probe $1.function(@2).return&lt;/code&gt;) are not available for inline functions. This limitation extends farther than it might look, because compiler optimization can implicitly make functions inline even if they aren't explicitly specified as inline by the developer.&lt;/li&gt; &lt;li&gt;Compiler reordering of statements can lead to some unexpected sequences in the control flow graph.&lt;/li&gt; &lt;li&gt;Recursive functions can't be probed. If the script monitors a function using recursion, one would see the line with the call followed by the line that is the entry point of the function. However, each time the function returns, the probe clears data and doesn't properly track the times for statements following the return.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;When you encounter a system problem in the future, take a look at the &lt;a href="https://sourceware.org/systemtap/examples/keyword-index.html"&gt;SystemTap examples&lt;/a&gt; to see whether there's an existing script that might help you diagnose the problem or provide a good starting point to create your own bespoke instrumentation. You can also learn more about SystemTap on the upstream project's &lt;a href="https://sourceware.org/systemtap/"&gt;home page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/05/write-systemtap-script-trace-code-execution-linux" title="Write a SystemTap script to trace code execution on Linux"&gt;Write a SystemTap script to trace code execution on Linux&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>William Cohen</dc:creator><dc:date>2022-07-05T07:00:00Z</dc:date></entry><entry><title>JBoss Tools and Red Hat CodeReady Studio for Eclipse 2022-06</title><link rel="alternate" type="text/html" href="https://tools.jboss.org/blog/4.24.0.final.html" /><category term="release" /><category term="jbosstools" /><category term="devstudio" /><category term="jbosscentral" /><category term="codereadystudio" /><author><name>jeffmaury</name></author><id>https://tools.jboss.org/blog/4.24.0.final.html</id><updated>2022-07-05T16:40:06Z</updated><published>2022-07-04T00:00:00Z</published><content type="html">&lt;div&gt;&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Happy to announce 4.24.0.Final build for Eclipse 2022-06.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Downloads available at &lt;a href="https://tools.jboss.org/downloads/jbosstools/2022-06/4.24.0.Final.html"&gt;JBoss Tools 4.24.0.Final&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-is-new"&gt;&lt;a class="anchor" href="#what-is-new"&gt;&lt;/a&gt;What is New?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Full info is at &lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.24.0.Final.html"&gt;this page&lt;/a&gt;. Some highlights are below.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="quarkus-tools"&gt;&lt;a class="anchor" href="#quarkus-tools"&gt;&lt;/a&gt;Quarkus Tools&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="improvement-to-the-new-quarkus-project-wizard"&gt;&lt;a class="anchor" href="#improvement-to-the-new-quarkus-project-wizard"&gt;&lt;/a&gt;Improvement to the new Quarkus project wizard&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When the new Quarkus project wizard was initially design, there were a few Quarkus extensions so it was not difficult to find one from the total list. Now that the Quarkus ecosystem is growing fast, it was difficult even of the extensions were grouped into categories.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In order to cope with this issue, the extensions and categories are now displayed in a tree (first level is categories, second level is extensions).&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This new tree can now be filtered through a text field. If user enter some characters, only extensions matching this filter will be displayed in the tree.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/quarkus/images/quarkus45.gif" alt="quarkus45" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="hibernate-tools"&gt;&lt;a class="anchor" href="#hibernate-tools"&gt;&lt;/a&gt;Hibernate Tools&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="hibernate-runtime-provider-updates"&gt;&lt;a class="anchor" href="#hibernate-runtime-provider-updates"&gt;&lt;/a&gt;Hibernate Runtime Provider Updates&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A number of additions and updates have been performed on the available Hibernate runtime providers.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect4"&gt; &lt;h5 id="runtime-provider-updates"&gt;&lt;a class="anchor" href="#runtime-provider-updates"&gt;&lt;/a&gt;Runtime Provider Updates&lt;/h5&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 6.0 runtime provider (Preview) now incorporates Hibernate Core version 6.0.2.Final and Hibernate Tools version 6.0.2.Final.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 5.6 runtime provider now incorporates Hibernate Core version 5.6.9.Final and Hibernate Tools version 5.6.9.Final.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 5.3 runtime provider now incorporates Hibernate Core version 5.3.27.Final and Hibernate Tools version 5.3.27.Final.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="and-more"&gt;&lt;a class="anchor" href="#and-more"&gt;&lt;/a&gt;And more…​&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;You can find more noteworthy updates in on &lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.24.0.Final.html"&gt;this page&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Enjoy!&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Jeff Maury&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;</content><summary>Happy to announce 4.24.0.Final build for Eclipse 2022-06. Downloads available at JBoss Tools 4.24.0.Final. What is New? Full info is at this page. Some highlights are below. Quarkus Tools Improvement to the new Quarkus project wizard When the new Quarkus project wizard was initially design, there were a few Quarkus extensions so it was not difficult to find one from the total list. Now that the Quarkus ecosystem is growing fast, it was difficult even of the extensions were grouped into categories. In order to cope with this issue, the extensions and categories are now displayed in a tree (first level is categories, second level is extensions). This new tree...</summary><dc:creator>jeffmaury</dc:creator><dc:date>2022-07-04T00:00:00Z</dc:date></entry><entry><title>Red Hat Developer roundup: Best of June 2022</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/30/red-hat-developer-roundup-best-june-2022" /><author><name>Josh Fruhlinger</name></author><id>79a05456-6c28-4b45-a502-e09bbf2fab00</id><updated>2022-06-30T07:00:00Z</updated><published>2022-06-30T07:00:00Z</published><summary type="html">&lt;p&gt;Welcome to our monthly recap of the articles we published in June! This month, we rolled out an armada of articles to help you build—and lock down—code on the platforms you trust. Here are the June highlights.&lt;/p&gt; &lt;h2&gt;Security for Kubernetes, Go, and beyond&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; is increasingly central to modern distributed and &lt;a href="https://developers.redhat.com/topics/containers"&gt;containerized&lt;/a&gt; development today, but it's a complex system that's difficult to secure. Ajmal Kohgadai and Andy Oram delivered a three-part series on Kubernetes security to help put your mind at ease:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/13/kubernetes-security-risks-keep-developers-night"&gt;Kubernetes security risks that keep developers up at night&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/14/4-tips-achieving-better-security-kubernetes"&gt;4 tips for achieving better security on Kubernetes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/15/best-practices-successful-devsecops"&gt;Best practices for successful DevSecOps&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Andy also rounded things out with a tour of &lt;a href="https://developers.redhat.com/articles/2022/06/20/8-open-source-kubernetes-security-tools"&gt;8 great open source Kubernetes security tools&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Red Hat Developer also took a look at security issues in the &lt;a href="http://Go"&gt;Go&lt;/a&gt; language. We provided a &lt;a href="https://developers.redhat.com/articles/2022/06/28/cross-site-scripting-explanation-and-prevention-go"&gt;primer on cross-site scripting&lt;/a&gt; that explained how you can prevent this type of attack when building applications in Go; we also showed you how to make sure your Go applications on RHEL &lt;a href="https://developers.redhat.com/articles/2022/05/31/your-go-application-fips-compliant"&gt;comply with the FIPS standard&lt;/a&gt; mandated for U.S. government contractors.&lt;/p&gt; &lt;p&gt;And finally, if you're dealing with good old-fashioned &lt;a href="https://developers.redhat.com/topics/c/"&gt;C&lt;/a&gt;, Serge Guelton and Siddhesh Poyarekar taught you how to &lt;a href="https://developers.redhat.com/articles/2022/06/02/use-compiler-flags-stack-protection-gcc-and-clang"&gt;use compiler flags to protect against stack-smashing attacks&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Dig deep into internals&lt;/h2&gt; &lt;p&gt;Some of our most popular articles of this month really got into the nitty-gritty of code execution, compilation, and performance monitoring. Thanks to Red Hat Developer's experts, you learned how to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Use the GNU Debugger to &lt;a href="https://developers.redhat.com/articles/2022/06/07/how-debug-stack-frames-and-recursion-gdb"&gt;debug stack frames and recursion&lt;/a&gt;, a common cause of programming errors.&lt;/li&gt; &lt;li&gt;Use the Bunsen test suite to track down &lt;a href="https://developers.redhat.com/articles/2022/06/09/detecting-nondeterministic-test-cases-bunsen"&gt;"flaky" tests that produce different outcomes&lt;/a&gt; when run repeatedly.&lt;/li&gt; &lt;li&gt;Monitor the performance of &lt;a href="https://developers.redhat.com/articles/2022/06/22/measuring-bpf-performance-tips-tricks-and-best-practices"&gt;BPF programs&lt;/a&gt; that themselves inspect other system activity.&lt;/li&gt; &lt;li&gt;Reveal potential performance problems, down to individual lines of code, with &lt;a href="https://developers.redhat.com/articles/2022/06/27/use-systemtap-example-script-trace-kernel-code-operation"&gt;SystemTap and one of its prewritten example scripts&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;SaaS architectures&lt;/h2&gt; &lt;p&gt;We continued a series that we &lt;a href="https://developers.redhat.com/articles/2022/05/18/saas-architecture-checklist-kubernetes"&gt;began in May&lt;/a&gt; about building and deploying Software as a service (SaaS) applications, and these also proved to be a big hit with readers. This month, you learned how to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Convert an &lt;a href="articles/2022/06/16/how-convert-web-application-software-service"&gt;existing web application into a SaaS service&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Develop a &lt;a href="https://developers.redhat.com/articles/2022/06/23/multi-cloud-storage-strategies-saas-applications"&gt;multi-cloud storage strategy&lt;/a&gt; to accommodate different environments where your SaaS service might be deployed.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Check out these articles and be on the lookout for future installments.&lt;/p&gt; &lt;h2&gt;Instrument containerized Java applications with Cryostat&lt;/h2&gt; &lt;p&gt;You probably have used Java Flight Recorder, an excellent tool for analyzing and understanding &lt;a href="https://developers.redhat.com/topics/java"&gt;Java&lt;/a&gt; workloads. It comes in handy during development or while workloads run in production. Cryostat takes that further by bringing the same functionality to containers and Kubernetes. You can check out our &lt;a href=""&gt;roundup of what's new in Cryostat 2.1&lt;/a&gt;, the latest version of the tool. You can also learn how to &lt;a href="https://developers.redhat.com/articles/2022/06/20/install-cryostat-new-helm-chart"&gt;install Cryostat using a Helm chart&lt;/a&gt;, which is suitable for demo purposes and simpler than using the Cryostat Operator.&lt;/p&gt; &lt;h2&gt;June 2022 on Red Hat Developer&lt;/h2&gt; &lt;p&gt;Here's the full lineup of articles published on Red Hat Developer so far this month:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/05/31/integrate-spring-boot-application-red-hat-data-grid"&gt;Integrate a Spring Boot application with Red Hat Data Grid&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/05/31/your-go-application-fips-compliant"&gt;Is your Go application FIPS compliant?&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/01/open-source-edge-detection-opencv-and-pachyderm"&gt;Open source edge detection with OpenCV and Pachyderm&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/01/join-red-hat-team-openjs-world-2022"&gt;Join the Red Hat team at OpenJS World 2022&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/02/how-create-kafka-consumers-and-producers-java"&gt;How to create Kafka consumers and producers in Java&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/02/use-compiler-flags-stack-protection-gcc-and-clang"&gt;Use compiler flags for stack protection in GCC and Clang&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/06/whats-new-version-27-red-hat-build-quarkus"&gt;What's new in version 2.7 of the Red Hat build of Quarkus&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/06/kafka-monthly-digest-may-2022"&gt;Kafka Monthly Digest: May 2022&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/07/thousands-pypi-and-rubygems-rpms-now-available-rhel-9"&gt;Thousands of PyPI and RubyGems RPMs now available for RHEL 9&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/07/how-debug-stack-frames-and-recursion-gdb"&gt;How to debug stack frames and recursion in GDB&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/08/eliminate-downtime-during-openshift-rolling-updates"&gt;Eliminate downtime during OpenShift rolling updates&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/08/9-awesome-updates-cryostat-21"&gt;9 awesome updates in Cryostat 2.1&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/09/detecting-nondeterministic-test-cases-bunsen"&gt;Detecting nondeterministic test cases with Bunsen&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/09/get-started-red-hat-openshift-connectors"&gt;Get started with Red Hat OpenShift Connectors&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/13/quick-way-translate-physical-addresses-virtual-ones"&gt;A quick way to translate physical addresses into virtual ones&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/13/kubernetes-security-risks-keep-developers-night"&gt;Kubernetes security risks that keep developers up at night&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/13/use-openvino-convert-speech-text"&gt;Use OpenVINO to convert speech to text&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/14/4-tips-achieving-better-security-kubernetes"&gt;4 tips for achieving better security on Kubernetes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/15/openssl-30-dealing-turkish-locale-bug"&gt;OpenSSL 3.0: Dealing with a Turkish locale bug&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/15/best-practices-successful-devsecops"&gt;Best practices for successful DevSecOps&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/16/learn-about-openshift-command-line-tools"&gt;Learn about OpenShift command-line tools&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/16/how-convert-web-application-software-service"&gt;How to convert a web application to Software-as-a-Service&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/20/install-cryostat-new-helm-chart"&gt;Install Cryostat with the new Helm chart&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/20/8-open-source-kubernetes-security-tools"&gt;8 open source Kubernetes security tools&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/21/distributed-tracing-opentelemetry-knative-and-quarkus"&gt;Distributed tracing with OpenTelemetry, Knative, and Quarkus&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/22/measuring-bpf-performance-tips-tricks-and-best-practices"&gt;Measuring BPF performance: Tips, tricks, and best practices&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/23/multi-cloud-storage-strategies-saas-applications"&gt;Multi-cloud storage strategies for SaaS applications&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/23/gpu-enablement-microshift"&gt;GPU enablement on MicroShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/24/road-jboss-eap-8"&gt;The road to JBoss EAP 8&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/27/use-systemtap-example-script-trace-kernel-code-operation"&gt;Use a SystemTap example script to trace kernel code operation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/28/cross-site-scripting-explanation-and-prevention-go"&gt;Cross-site scripting: Explanation and prevention with Go&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/29/how-add-libraries-nodejs-container-s2i"&gt;How to add libraries to a Node.js container with S2I&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/30/red-hat-developer-roundup-best-june-2022" title="Red Hat Developer roundup: Best of June 2022"&gt;Red Hat Developer roundup: Best of June 2022&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Josh Fruhlinger</dc:creator><dc:date>2022-06-30T07:00:00Z</dc:date></entry><entry><title type="html">This Week in JBoss - June 30th 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-06-30.html" /><category term="quarkus" /><category term="java" /><category term="kubernetes" /><category term="openshift" /><category term="security" /><category term="xss" /><category term="golang" /><category term="go" /><category term="javascript" /><category term="graphql" /><author><name>Stefan Sitani</name><uri>https://www.jboss.org/people/stefan-sitani</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-06-30.html</id><updated>2022-06-30T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, java, kubernetes, openshift, security, xss, golang, go, javascript, graphql"&gt; &lt;h1&gt;This Week in JBoss - June 30th 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Hello and welcome to JBoss Editorial June 30th edition! We are nearing the end of the second week of summer, and most of us are already looking forward to our vacation plans. And while for some the next 2 months will be a time to relax, slow down, and take things a little easy, progress and innovation never really stop! So for those of you interested in the latest and the greatest that your favorite project have to offer, here are this week’s highlights from around the JBoss community.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_releases_releases_releases"&gt;Releases, releases, releases!&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Here are the releases from the JBoss Community for this edition:&lt;/p&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://camel.apache.org/blog/2022/06/camel-quarkus-release-2.10.0/"&gt;Camel Quarkus 2.10.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://debezium.io/blog/2022/06/21/debezium-1-9-4-final-released/"&gt;Debezium 1.9.4.Final&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org/2022/06/keycloak-1802-released"&gt;Keycloak 18.0.2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/06/kogito-1-23-0-released.html"&gt;Kogito 1.23.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/smallrye/smallrye-mutiny/releases/tag/1.6.0"&gt;Mutiny 1.6.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-10-0-final-released/"&gt;Quarkus 2.10.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_articles_blogs"&gt;Articles &amp;#38; Blogs&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="sect2"&gt; &lt;h3 id="_how_to_convert_a_web_application_to_software_as_a_service"&gt;How to convert a web application to Software-as-a-Service&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/16/how-convert-web-application-software-service#"&gt;How to convert a web application to Software-as-a-Service&lt;/a&gt; by Bob Reselman&lt;/p&gt; &lt;p&gt;Bob Reselman delves into the "brownfield" approach to redeveloping your web application into a SaaS platform. Starting off with a well-laid out example business scenario, Bob walks you through the key steps of the process from analyzing your business logic patterns, separating configuration from code, picking an appropriate service architecture, to leveraging the benefits offered by containerization and Kubernetes to ensure that you’ll always be able to scale your services to match the growth of your business.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_multi_cloud_storage_strategies_for_saas_applications"&gt;Multi-cloud storage strategies for SaaS applications&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/23/multi-cloud-storage-strategies-saas-applications#"&gt;Multi-cloud storage strategies for SaaS applications&lt;/a&gt; by Michael Hrivnak&lt;/p&gt; &lt;p&gt;In the fourth entry to the ongoing &lt;a href="https://developers.redhat.com/articles/2022/05/18/saas-architecture-checklist-kubernetes"&gt;&lt;em&gt;SaaS architecture checklist&lt;/em&gt;&lt;/a&gt; blog series Michael Hrivnak compares software-defined storage (SDS) technologies that help developers create optimized data storage solutions for use in multi-tenant cloud environments. The first part of Michael’s article deals with the broader technical consideration of how SDS can help developers minimize platform-specific development work, followed by an overview of Red Hat’s current cloud storage technology offerings. In the latter section, Michael provides some insight into combining these offerings to create solutions that provide customers with self-scaling, self-managed, low-latency data storage capabilities.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_cross_site_scripting_explanation_and_prevention_with_go"&gt;Cross-site scripting: Explanation and prevention with Go&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/28/cross-site-scripting-explanation-and-prevention-go#"&gt;Cross-site scripting: Explanation and prevention with Go&lt;/a&gt; by Sandipan Roy&lt;/p&gt; &lt;p&gt;Cross-site scripting (XSS) attacks have recently become a topic of interest among application security experts in the cloud native developer community. In his tutorial, Sandipan breaks down the mechanism of executing an XSS attack using malicious JavaScript elements and follows up by outlining 3 strategies for coding in Go that you can use to protect your applications against different types of XSS attacks (Sandipan mentions Stored, Reflected and DOM-based XSS attacks). The tutorial is richly supplemented by code examples and plenty of additional information context. Even though this article is a little outside our usual focus area, it is definitely worth a read, especially for those of you interested in buffing up your application security knowledge.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_how_to_build_graphql_applications_with_quarkus"&gt;How to build GraphQL applications with Quarkus&lt;/h3&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/soa-cloud/quarkus/how-to-build-graphql-applications-with-quarkus/"&gt;How to build GraphQL applications with Quarkus&lt;/a&gt; by Francesco Marchioni&lt;/p&gt; &lt;p&gt;In a follow-up to his &lt;a href="http://www.mastertheboss.com/eclipse/eclipse-microservices/getting-started-with-graphql-using-java-applications/"&gt;earlier article&lt;/a&gt; about GraphQL on WildFly, Francesco is back with another tutorial, this time about GraphQL and Quarkus. The article opens with a brief discussion of the advantages that GraphQL’s schema based data access model has over REST APIs. Francesco then moves on to showing how you can use &lt;a href="https://code.quarkus.io"&gt;code.quarkus.io&lt;/a&gt; to create a Quarkus application that supports GraphQL using the MicroProfile-compliant SmallRye GraphQL extensions. The test of the tutorial is a step-by-step guide to writing the service class of the application and a GraphQL API class that handles the Query and Mutation operations supported by GraphQL. At this point, Francesco offers a bit of comparison between the different ways that data access operations work in GraphQL as opposed to REST. The tutorial ends with sections detailing how you can test your applications using either the GraphQL UI provided by the extension, or the SmallRye MicroProfile GraphQL client API. In a manner typical of most of Francesco’s tutorials, this one also contains a link to a repository with the code for this example project. And those of you interested in learning more about GraphQL in Quarkus, check out &lt;em&gt;Quarkus Insights&lt;/em&gt; episode #93. You can find the link to it in the &lt;em&gt;Videos&lt;/em&gt; section of this week’s editorial.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_videos"&gt;Videos&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;This week there was plenty of fresh content to choose from, so please enjoy some of my top video picks:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/qqztCp5Bvbg"&gt;Quarkus Insights #94: Scientific Games meets Quarkus&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/PHWOzzusfrY"&gt;Quarkus Insights #93: The Latest with GraphQL and Quarkus&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/w5SBQpAQ8m8"&gt;Using Minecraft as an Observability Client: A demo by Holly Cummins&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/00g-gBIYpsU"&gt;Quinoa: A modern Quarkus UI with no hassles: DevNation talk by Andy Damevin&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/LhTR_ECSaAo"&gt;Debugging natively compiled Java code with NativeJDB: A demo by Ansu Varghese&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/4HI8bVd8JFc"&gt;JNation.PT 2022: All Quarkus Track Sessions Recorded&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt;&lt;em&gt;That’s all for today! Please join us again in two weeks for another round of our JBoss editorial! Stay safe and enjoy your summer vacation!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/stefan-sitani.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Stefan Sitani&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Stefan Sitani</dc:creator></entry><entry><title>How to add libraries to a Node.js container with S2I</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/06/29/how-add-libraries-nodejs-container-s2i" /><author><name>Michael Dawson</name></author><id>2c02fc97-0cf3-45eb-a771-b0ae7fa2d218</id><updated>2022-06-29T07:00:00Z</updated><published>2022-06-29T07:00:00Z</published><summary type="html">&lt;p&gt;The &lt;a href="https://github.com/openshift/source-to-image"&gt;Source-to-Image&lt;/a&gt; (S2I) toolkit allows you to easily build application &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; images for &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;OpenShift&lt;/a&gt; deployment. Red Hat provides S2I images for a number of languages including &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt;. For example, this is the image for &lt;a href="https://catalog.redhat.com/software/containers/ubi8/nodejs-16/615aee9fc739c0a4123a87e1?container-tabs=overview"&gt;Node.js 16.x&lt;/a&gt;. To learn more about using the Red Hat images versus other Node.js images, check out the &lt;a href="https://developers.redhat.com/articles/2021/08/26/introduction-nodejs-reference-architecture-part-5-building-good-containers"&gt;Building good containers&lt;/a&gt; section of the Node.js reference architecture.&lt;/p&gt; &lt;p&gt;If you have an application with a &lt;code&gt;package.json&lt;/code&gt; that includes an &lt;code&gt;npm start&lt;/code&gt; command, deploying that application using &lt;a href="https://github.com/nodeshift/nodeshift"&gt;nodeshift&lt;/a&gt; (which supports S2I) can be as easy as running &lt;code&gt;nodeshift&lt;/code&gt; in the directory with the &lt;code&gt;package.json&lt;/code&gt;. It will package your application and deploy to your current OpenShift project.&lt;/p&gt; &lt;p&gt;Super easy, right? Well, most of the time. It might get a bit more complicated if your application uses native add-ons that need additional libraries not installed in the Node.js container image. For example, if you want to use the &lt;a href="https://www.npmjs.com/package/odbc"&gt;odbc&lt;/a&gt; package, you will need some ODBC libraries and the odbc client for the database you want to connect to. More specifically, if you want to use the odbc package with the MySQL database, install the additional libraries through the following RPMs:&lt;/p&gt; &lt;ul&gt; &lt;li aria-level="1"&gt;unixODBC&lt;/li&gt; &lt;li aria-level="1"&gt;mysql-connector-odbc&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;So how do you pull all this off? The following steps worked for me:&lt;/p&gt; &lt;ol&gt; &lt;li aria-level="1"&gt;Building an image that extends the Node.js container image by adding the required RPMs.&lt;/li&gt; &lt;li aria-level="1"&gt;Deploying the application with Nodeshift and instructing it to use this image.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;We'll dive into these steps over the remainder of this article to show you how it's done.&lt;/p&gt; &lt;h2&gt;Build the extended image&lt;/h2&gt; &lt;p&gt;I used a &lt;code&gt;BuildConfig&lt;/code&gt; to build the extended image:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; apiVersion: build.openshift.io/v1 kind: BuildConfig metadata: name: odbc-base spec: source: dockerfile: | FROM registry.access.redhat.com/ubi8/nodejs-16 USER 0 RUN curl https://repo.mysql.com/mysql80-community-release-el8-1.noarch.rpm &gt;mysql80-community-release-el8-1.noarch.rpm RUN dnf localinstall -y mysql80-community-release-el8-1.noarch.rpm RUN dnf install --nogpgcheck -y unixODBC mysql-connector-odbc RUN sed -i -e 's|Driver64=/usr/lib64/libmyodbc5.so|Driver64=/usr/lib64/libmyodbc8w.so|g' /etc/odbcinst.ini USER 1001 strategy: type: Docker output: to: kind: ImageStreamTag name: odbc-base:latest &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;I saved that in &lt;code&gt;odbc-base.yaml&lt;/code&gt; and applied it with:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;oc apply -f odbc-base.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This creates a new OpenShift ImageStream named &lt;code&gt;odbc-base&lt;/code&gt;, which extends the base Node.js image (in the &lt;code&gt;FROM&lt;/code&gt; line) by installing the &lt;code&gt;unixODBC&lt;/code&gt; and &lt;code&gt;mysql-connector-odbc&lt;/code&gt; RPMs (&lt;code&gt;RUN dnf install --nogpgcheck -y unixODBC mysql-connector-odbc&lt;/code&gt;). The rest of the lines in the Dockerfile are either set up to make the RPMs available or a workaround for what appears to be a bug in the &lt;code&gt;mysql-connector-odbc&lt;/code&gt; installation.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;USER 0&lt;/code&gt; and &lt;code&gt;USER 1001&lt;/code&gt; lines are needed to set the user to root so that the &lt;code&gt;dnf&lt;/code&gt; commands can run, and then to set the user back to what is expected by the S2I image when it runs.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;curl&lt;/code&gt; and &lt;code&gt;localinstall&lt;/code&gt; commands are needed to add the repository from which the &lt;code&gt;mysql-connector-odbc&lt;/code&gt; RPM comes.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;sed&lt;/code&gt; command works around a bug in the &lt;code&gt;mysql-connector-odbc&lt;/code&gt; install where the &lt;code&gt;odbcinst.ini&lt;/code&gt; configuration file points to the wrong library for MySQL in the default install.&lt;/p&gt; &lt;p&gt;Once I applied the build config with &lt;code&gt;oc apply -f odbc-base.yaml&lt;/code&gt;, I completed the following steps as an Administrator in the OpenShift GUI:&lt;/p&gt; &lt;ol&gt; &lt;li aria-level="1"&gt;Create an image stream named &lt;code&gt;odbc-base&lt;/code&gt;. If you don’t do this, the build in step 2 will wait for the image stream before starting.&lt;/li&gt; &lt;li aria-level="1"&gt;Start a build for the build config making &lt;code&gt;odbc-base:latest&lt;/code&gt; available.&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Deploy with the extended image&lt;/h2&gt; &lt;p&gt;Once you have the extended image in OpenShift as the &lt;code&gt;odbc-base&lt;/code&gt; image stream, deploy it as follows:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;nodeshift --imageStream=odbc-base&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;If you ever wondered how to handle Node.js packages that require additional system libraries using S2I, I hope this article has helped. Only a few additional steps are required, and you are back to a single &lt;a href="https://github.com/nodeshift/nodeshift"&gt;nodeshift&lt;/a&gt; install.&lt;/p&gt; &lt;p&gt;If you want to learn more about what Red Hat is up to on the Node.js front, check out our &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js landing page&lt;/a&gt; or the &lt;a href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview"&gt;Node.js reference architecture series&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/06/29/how-add-libraries-nodejs-container-s2i" title="How to add libraries to a Node.js container with S2I"&gt;How to add libraries to a Node.js container with S2I&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Michael Dawson</dc:creator><dc:date>2022-06-29T07:00:00Z</dc:date></entry><entry><title>Sharing your Container Development Environment with Red Hat Openshift Dev Spaces (formerly CodeReady Workspaces)</title><link rel="alternate" href="https://developers.redhat.com/crw-fmi" /><author><name>dtidwell</name></author><id>af4274f5-76c8-4ea9-9b15-4149731024ce</id><updated>2022-06-29T01:49:57Z</updated><published>2022-06-29T01:49:57Z</published><summary type="html" /><dc:creator>dtidwell</dc:creator><dc:date>2022-06-29T01:49:57Z</dc:date></entry><entry><title>Hello World for Red Hat OpenShift Dev Spaces (formerly CodeReady Workspaces)</title><link rel="alternate" href="https://developers.redhat.com/crw-hw" /><author><name>dtidwell</name></author><id>fa238d90-bc15-45f4-9d0a-386dd4082a59</id><updated>2022-06-29T01:49:40Z</updated><published>2022-06-29T01:49:40Z</published><summary type="html">&lt;h2&gt;About This Page&lt;/h2&gt; &lt;p&gt;This page has two parts:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Install OpenShift Dev Spaces (Dev Spaces).&lt;/li&gt; &lt;li&gt;Get a "Hello World" example application open in OpenShift Dev Spaces.&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Install via Operator Hub&lt;/h2&gt; &lt;p&gt;There is a recommended method for creating an OpenShift Dev Spaces instance in your OpenShift cluster. Explore&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_dev_spaces/3.0/html-single/administration_guide/index#preparing-the-installation"&gt; the administrative guide&lt;/a&gt; for more information.&lt;/p&gt; &lt;h2&gt;Install via command line&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Important note: Creating the OpenShift Dev Spaces instance using the command line is supported for versions of OpenShift 4.10 or higher. It is recommended that you use the OpenShift Dev Spaces Operator, located in the Operator Hub, to install Dev Spaces.&lt;/strong&gt;&lt;/p&gt; &lt;h3 id="install-to-ocp-or-osd_download-and-unpack-the-deployment-script"&gt;1. Download and install the command line tool, &lt;code class="code-style"&gt;dsc&lt;/code&gt;&lt;/h3&gt; &lt;p&gt;&lt;em&gt;3 minutes&lt;/em&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Navigate to &lt;a href="https://developers.redhat.com/products/openshift-dev-spaces/download"&gt;https://developers.redhat.com/products/openshift-dev-spaces/download&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Download the OpenShift Dev Spaces CLI management tool archive for version 3.0.&lt;/li&gt; &lt;li&gt;Extract the archive.&lt;/li&gt; &lt;li&gt;Place the extracted binary in your &lt;code&gt;$PATH&lt;/code&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;h3 id="install-to-ocp-or-osd_run-the-deployment-script"&gt;2. Use &lt;code class="code-style"&gt;dsc&lt;/code&gt; to create an OpenShift Dev Spaces instance in your cluster&lt;/h3&gt; &lt;p&gt;&lt;em&gt;10 minutes&lt;/em&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Log into your OpenShift cluster with cluster-admin rights.&lt;/li&gt; &lt;li&gt;From your command line, run the command:  &lt;pre&gt; &lt;code&gt;dsc server:start&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;This will create an OpenShift Dev Spaces instance in the OpenShift namespace/project `openshift-devspaces` (which will be created if it does not exist). When it is finished, the Dev Spaces URL will be returned.&lt;/p&gt; &lt;h2&gt;Run a sample workspace&lt;/h2&gt; &lt;p&gt;After logging in to your Dev Spaces instance, select any sample project.&lt;/p&gt; &lt;h2&gt;Run a workspace for your own Git project&lt;/h2&gt; &lt;p&gt;After logging in to your Dev Spaces instance, enter the Git Repo URL and click `Create &amp; Open`. If your project does not already include a devfile.yaml, a default configuration will be loaded. To learn more about devfiles, see &lt;a href="https://devfile.io/docs/devfile/2.1.0/user-guide/" target="_blank"&gt;https://devfile.io/docs/devfile/2.1.0/user-guide/&lt;/a&gt;&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/crw-hw" title="Hello World for Red Hat OpenShift Dev Spaces (formerly CodeReady Workspaces)"&gt;Hello World for Red Hat OpenShift Dev Spaces (formerly CodeReady Workspaces)&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>dtidwell</dc:creator><dc:date>2022-06-29T01:49:40Z</dc:date></entry><entry><title>Debugging natively compiled Java code with NativeJDB</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/nativejdb-debugger-for-native-images/&#xA;            " /><author><name>Mandana Vaziri (https://twitter.com/mandana_vaziri)</name></author><id>https://quarkus.io/blog/nativejdb-debugger-for-native-images/</id><updated>2022-06-29T00:00:00Z</updated><published>2022-06-29T00:00:00Z</published><summary type="html">Co-authored by: Ansu Varghese, Research Software Engineer, IBM In collaboration with: Max Andersen, Dimitris Andreadis, Andrew Dinn, Stuart Douglas, Jason Greene, David Grove, David Lloyd, Thomas Qvarnstrom, Foivos Zakkak, Galder Zamarreno (IBM Research and Red Hat) Quarkus is a cloud-native Java development framework, which allows Java code to be mapped...</summary><dc:creator>Mandana Vaziri (https://twitter.com/mandana_vaziri)</dc:creator><dc:date>2022-06-29T00:00:00Z</dc:date></entry><entry><title type="html">Kogito 1.23.0 released!</title><link rel="alternate" href="https://blog.kie.org/2022/06/kogito-1-23-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2022/06/kogito-1-23-0-released.html</id><updated>2022-06-28T08:38:11Z</updated><content type="html">We are glad to announce that the Kogito 1.23.0 release is now available! This goes hand in hand with , release. From a feature point of view, we have included a series of new features and bug fixes, including: * Added endpoint to get source file content from a specific workflow * Added the get workflow source to the data index gateway API. * Token propagation support for OpenAPI extension * Runtime persistence now allows using Java serialization instead of protobuf definitions * gRPC operation type to Serverless functions BREAKING CHANGES * Source files add-on rest endpoint URL have been changed from ‘/management/process/{Id}/sources’ to ‘/management/processes/{processId}/sources’ to be aligned with the other management rest endpoints. * Removed deprecated add-ons, for a mapping of new artifact id visit . For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.20.0 artifacts are available at the . A detailed changelog for 1.23.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry></feed>
